{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Tensor Parallelism using the SageMaker Model Parallelism Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook walks you through how to use the tensor parallelism feature provided by the SageMaker model parallelism library. You'll learn how to train the GPT-J model with tensor parallelism on a synthetic text data.\n",
    "\n",
    "**Note**: To run this example training job, you must be in `us-west-2`. The preview version of container images are available only in those two regions.\n",
    "\n",
    "## Install and Upgrade Libraries\n",
    "\n",
    "The SageMaker model parallelism library's tensor parallelism feature requires the SageMaker Python SDK and the SageMaker Experiments library. Run the following cell to install or upgrade the libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** To finish applying the changes, you must restart the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run once, restart kernel, then comment out this cell\n",
    "# update sagemaker to the latest 2.x version\n",
    "# ! pip install -qU pip\n",
    "# ! pip install -qU \"sagemaker>=2,<3\"\n",
    "# ! pip install -qU sagemaker-experiments\n",
    "\n",
    "# import IPython\n",
    "# IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import and check if the SageMaker Python SDK version is successfully set to the latest version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.86.0\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "print(sagemaker.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon SageMaker Initialization\n",
    "\n",
    "This private preview feature is available to use in `us-east-1` and `us-west-2`.\n",
    "Throughout this example, you'll use a training script of GPT model and a text dataset.\n",
    "\n",
    "Run the following cell to import SageMaker modules and retrieve information of your current SageMaker work environment: your AWS account ID, the AWS Region you are using to run the notebook, and the ARN of your Amazon SageMaker execution role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SageMaker Execution Role:SageMakerRole\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS account:855988369404\n",
      "AWS region:us-west-2\n",
      "CPU times: user 190 ms, sys: 43.8 ms, total: 234 ms\n",
      "Wall time: 700 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "from smexperiments.experiment import Experiment\n",
    "from smexperiments.trial import Trial\n",
    "import boto3\n",
    "\n",
    "# If running in Sagemaker notebook this can stay commented\n",
    "# os.environ[\"AWS_PROFILE\"] = \"sm\"\n",
    "\n",
    "# supported regions only us-west-2 and us-east-1\n",
    "# preview images are only in these two regions\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"us-west-2\"\n",
    "\n",
    "# role = get_execution_role() # provide a pre-existing role ARN as an alternative to creating a new role\n",
    "role = \"SageMakerRole\"\n",
    "print(f'SageMaker Execution Role:{role}')\n",
    "\n",
    "client = boto3.client('sts')\n",
    "account = client.get_caller_identity()['Account']\n",
    "print(f'AWS account:{account}')\n",
    "\n",
    "session = boto3.session.Session()\n",
    "region = session.region_name\n",
    "print(f'AWS region:{region}')\n",
    "\n",
    "sm_boto_client = boto3.client(\"sagemaker\")\n",
    "sagemaker_session = sagemaker.session.Session(boto_session=session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Amazon S3 Bucket Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you need to specify the paths for training data to be used by your job. The bucket used must be in the same region as where training will run. As part of the private preview artifacts, we provide a synthetic dataset that you can use to quickly get started in 'smdistributed-modelparallel-preview' bucket. This bucket is in us-west-2, and we recommend you copy the data to your own bucket and update the paths in the next cell to avoid any cross-account permission issues depending on your IAM role permissions.\n",
    "\n",
    "After you successfully run this example tensor parallel training job, you can modify the S3 bucket to where your own dataset is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if region == 'us-east-1':\n",
    "    s3_train_bucket = \"s3://cakarak-playground/gpt-debug/train-synthetic/\"\n",
    "    s3_test_bucket = \"s3://cakarak-playground/gpt-debug/val-synthetic/\"\n",
    "elif region == 'us-west-2':\n",
    "    s3_train_bucket = \"s3://smdistributed-modelparallel-preview/synthetic-gpt-data/train_synthetic/\"\n",
    "    s3_test_bucket = \"s3://smdistributed-modelparallel-preview/synthetic-gpt-data/val_synthetic/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below bucket will store output artifacts of the training job. You can modify this as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_bucket = f\"s3://sagemaker-{region}-{account}/smp-tensorparallel-beta/gpj_synthetic_simpletrainer_outputdir/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Data Channels for SageMaker Training\n",
    "\n",
    "In this step, you define SageMaker training data channels using the above buckets.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set use_fsx to False by default\n",
    "# Set below var to True if you want to use fsx (see next cell)\n",
    "use_fsx = False\n",
    "if not use_fsx:\n",
    "    train = sagemaker.inputs.TrainingInput(s3_train_bucket, distribution='FullyReplicated', s3_data_type='S3Prefix')\n",
    "    test = sagemaker.inputs.TrainingInput(s3_test_bucket, distribution='FullyReplicated', s3_data_type='S3Prefix')\n",
    "    data_channels = {'train': train, 'test': test}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup fsx and use fsx for data channels and checkpoints\n",
    "\n",
    "While the above option is easier to setup, using an FSX can be beneficial for performance when dealing with large input sizes and large model sizes. If you are using models above 13B, checkpointing should be done using FSX. \n",
    "\n",
    "Please see the instructions [here](https://github.com/aws/amazon-sagemaker-examples/blob/master/advanced_functionality/distributed_tensorflow_mask_rcnn/mask-rcnn-scriptmode-fsx.ipynb), to create the FSx lustre filesystem and import the dataset from the S3 bucket to your fsx filesystem. Note that the FSX must be created in a private subnet with internet gateway to ensure that training job has access to the internet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instructions obtained from:\n",
    "# https://github.com/aws/amazon-sagemaker-examples/blob/master/advanced_functionality/distributed_tensorflow_mask_rcnn/mask-rcnn-scriptmode-fsx.ipynb\n",
    "\n",
    "if use_fsx:\n",
    "    from sagemaker.inputs import FileSystemInput\n",
    "\n",
    "    # Specify FSx Lustre file system id.\n",
    "    file_system_id = \"fs-01bdca7270e7a4c38\"\n",
    "    \n",
    "    # Specify the SG and subnet used by the FSX, these are passed to SM Estimator so jobs use this as well\n",
    "    fsx_security_group_id = \"sg-0187f4ddd05b7241c\"\n",
    "    fsx_subnet = \"subnet-0ae2d781b32d8b3d0\"\n",
    "    \n",
    "    # Specify directory path for input data on the file system. \n",
    "    # You need to provide normalized and absolute path below.\n",
    "    # Your mount name can be provided by you when creating fsx, or generated automatically.\n",
    "    # You can find this mount_name on the FSX page in console. \n",
    "    # Example of fsx generated mount_name: \"3x5lhbmv\"\n",
    "    base_path = \"/3x5lhbmv\"\n",
    "\n",
    "    # Specify your file system type.\n",
    "    file_system_type = 'FSxLustre'\n",
    "\n",
    "    train = FileSystemInput(file_system_id=file_system_id,\n",
    "                            file_system_type=file_system_type,\n",
    "                            directory_path=base_path,\n",
    "                            file_system_access_mode=\"rw\")\n",
    "\n",
    "    data_channels = {\"train\": train, \"test\": train}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Hyperparameters, Metric Definitions, and MPI Options\n",
    "The following `hyperparameters` dictionary is to pass arguments to the training script (`train_gpt_simple.py`) and set the model parallel configuration when creating the training job.\n",
    "\n",
    "You can also add custom mpi flags. By default, we have `--mca btl_vader_single_copy_mechanism none` to remove unnecessary logs.\n",
    "\n",
    "Next we add a base metric definitions to enable the metric upload in SageMaker. You can add any further metric definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'max_steps': 100,\n",
    "                   'seed': 12345,\n",
    "                   'fp16': 1,\n",
    "                   'lr': 2.e-4,\n",
    "                   'lr_decay_iters': 125000,\n",
    "                   'min_lr': 0.00001,\n",
    "                   'lr-decay-style': 'linear',\n",
    "                   'warmup': 0.01,\n",
    "                   'num_kept_checkpoints': 5,\n",
    "                   'checkpoint_freq': 200,\n",
    "                   'validation_freq': 1000,\n",
    "                   'logging_freq': 10,\n",
    "                   'save_final_full_model': 1,\n",
    "                   'skip_full_optimizer': 1,\n",
    "                   'shard_optimizer_state': 1,\n",
    "                   'activation_checkpointing': 1,\n",
    "                   'activation_strategy': 'each',\n",
    "                   'optimize': 'speed',\n",
    "                    # below flag loads model and optimizer state from checkpoint_s3_uri\n",
    "                    # 'load_partial': 1,\n",
    "                  }\n",
    "\n",
    "\n",
    "if use_fsx:\n",
    "    # make sure to update paths for training-dir and test-dir based on the paths of datasets in fsx\n",
    "    # If you want to resume training, set checkpoint-dir to the same path as a previous job.\n",
    "    SM_TRAIN_DIR = \"/opt/ml/input/data/train\"\n",
    "    hyperparameters['checkpoint-dir'] = f\"{SM_TRAIN_DIR}/checkpointdir-job2\"\n",
    "    hyperparameters['model-dir'] = f\"{SM_TRAIN_DIR}/modeldir-job2\"\n",
    "    hyperparameters['training-dir'] = f\"{SM_TRAIN_DIR}/datasets/pytorch_gpt2/train_synthetic\"\n",
    "    hyperparameters['test-dir'] = f\"{SM_TRAIN_DIR}/datasets/pytorch_gpt2/val_synthetic\"\n",
    "\n",
    "# The checkpoint path (hyperparameters['checkpoint-dir'] or checkpoint_s3_uri) is not unique per job. \n",
    "# You need to modify as needed for different runs. \n",
    "# If same path is used for unrelated runs, this may increase time when downloading unnecessary checkpoints, \n",
    "# and cause conflicts when loading checkpoints.\n",
    "\n",
    "\n",
    "mpioptions = \"-x NCCL_DEBUG=WARN -x SMDEBUG_LOG_LEVEL=ERROR \"\n",
    "mpioptions += \"-x SMP_DISABLE_D2D=1 -x SMP_D2D_GPU_BUFFER_SIZE_BYTES=1 -x SMP_NCCL_THROTTLE_LIMIT=1 \"\n",
    "mpioptions += \"-x FI_EFA_USE_DEVICE_RDMA=1 -x FI_PROVIDER=efa -x RDMAV_FORK_SAFE=1\"\n",
    "\n",
    "metric_definitions = [{\"Name\": \"base_metric\", \"Regex\": \"<><><><><><>\"}] # Add your custom metric definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the model configuration below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = 'gptj-6b'\n",
    "\n",
    "if model_config == 'gptj-6b':\n",
    "    model_params = {        \n",
    "        'max_context_width': 512, \n",
    "        'hidden_width': 4096, \n",
    "        'num_layers': 28, \n",
    "        'num_heads': 16,\n",
    "        \n",
    "        'tensor_parallel_degree': 8,\n",
    "        'pipeline_parallel_degree': 2,\n",
    "\n",
    "        'train_batch_size': 16,\n",
    "        'val_batch_size': 16,\n",
    "        'prescaled_batch': 1,\n",
    "    }\n",
    "else:\n",
    "    raise RuntimeError(\"Unknown model config\")\n",
    "\n",
    "for k, v in model_params.items():\n",
    "    hyperparameters[k] = v\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up SageMaker Studio Experiment\n",
    "Create or load [SageMaker Experiment](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments.html) for the example training job. This will create an experiment trial object in SageMaker Studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "# Specify your experiment name\n",
    "experiment_name = \"smp-gptj\"\n",
    "# Specify your trial name\n",
    "trial_name = f'{experiment_name}-trial1' \n",
    "\n",
    "all_experiment_names = [exp.experiment_name for exp in Experiment.list()]\n",
    "# Load the experiment if it exists, otherwise create \n",
    "if experiment_name not in all_experiment_names:\n",
    "    experiment = Experiment.create(experiment_name=experiment_name, sagemaker_boto_client=sm_boto_client)\n",
    "else:\n",
    "    experiment = Experiment.load(experiment_name=experiment_name, sagemaker_boto_client=sm_boto_client)\n",
    "\n",
    "# Create the trial\n",
    "trial = Trial.create(\n",
    "        trial_name=\"smp-{}-{}\".format(trial_name, strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())),\n",
    "        experiment_name=experiment.experiment_name,\n",
    "        sagemaker_boto_client=sm_boto_client,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Essential Parameters for a SageMaker Training Job\n",
    "\n",
    "Next, you will use the [`SageMaker Estimator API`](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html) to define a SageMaker Training Job, passing values through the following parameters for training job name, the number of EC2 instances, the instance type, and the size of the volume attached to the instances. \n",
    "\n",
    "* `instance_count`\n",
    "* `instance_type`\n",
    "* `volume_size`\n",
    "* `base_job_name`\n",
    "\n",
    "### Update the Type and Number of EC2 Instance to Use\n",
    "\n",
    "The instance type and the number of instances you specify to the `instance_type` and `instance_count` parameters, respectively, will determine the total number of GPUs (world size).\n",
    "\n",
    "$$ \\text{(world size) = (the number of GPUs on a single instance)}\\times\\text{(the number of instance)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_type = 'ml.p4d.24xlarge'\n",
    "\n",
    "instance_count = 2\n",
    "\n",
    "# set to the number of GPUs on that instance\n",
    "processes_per_host = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To look up the number of GPUs of different instance types, see [Amazon EC2 Instance Types](https://aws.amazon.com/ec2/instance-types/). Use the section **Accelerated Computing** to see general purpose GPU instances. Note that, for example, a given instance type `p4d.24xlarge` has a corresponding instance type `ml.p4d.24xlarge` in SageMaker.\n",
    "For SageMaker supported `ml` instances and cost information, see [Amazon SageMaker Pricing](https://aws.amazon.com/sagemaker/pricing/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attach an EBS Volume to the Training Instance\n",
    "The volume size you specify in `volume_size` must be larger than your input data size. In this example, the volume size is set to 500GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_size=500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify a Base Job Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_str = instance_type.split('.')[1] + instance_type.split('.')[2][:3]\n",
    "pp_degree = hyperparameters['pipeline_parallel_degree']\n",
    "tp_degree = hyperparameters['tensor_parallel_degree']\n",
    "base_job_name = f'smp-{model_config}-{machine_str}-tp{tp_degree}-pp{pp_degree}-bs{hyperparameters[\"train_batch_size\"]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_fsx:\n",
    "    # If you want to resume training, set checkpoint_s3_uri to the same path as a previous job.\n",
    "    # Previous checkpoint to load must have same model config.\n",
    "    checkpoint_bucket = f\"s3://sagemaker-{region}-{account}/\"\n",
    "    checkpoint_s3_uri = f\"{checkpoint_bucket}/experiments/gpt_synthetic_simpletrainer_checkpoints/{base_job_name}/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a SageMaker PyTorch Estimator\n",
    "\n",
    "The following cell constructs a PyTorch estimator using the parameters defined above. To see how the SageMaker tensor parallelism modules and functions are applied to the script, see the `train_gpt_simple.py` file and the private preview documentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {}\n",
    "if use_fsx:\n",
    "    # Use the security group and subnet that was used to create the fsx filesystem\n",
    "    kwargs[\"security_group_ids\"] = [fsx_security_group_id]\n",
    "    kwargs[\"subnets\"] = [fsx_subnet]\n",
    "\n",
    "smp_estimator = HuggingFace(\n",
    "        entry_point=\"train_gptj_simple.py\",\n",
    "        source_dir=os.getcwd(),\n",
    "        role=role,\n",
    "        instance_type=instance_type,\n",
    "        image=\"763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-training:1.10.2-transformers4.17.0-gpu-py38-cu113-ubuntu20.04-v1.0\",\n",
    "        volume_size=volume_size,\n",
    "        instance_count=instance_count,\n",
    "        sagemaker_session=sagemaker_session,\n",
    "        distribution={\n",
    "            \"mpi\": {\n",
    "                \"enabled\": True,\n",
    "                \"processes_per_host\": processes_per_host,\n",
    "                \"custom_mpi_options\": mpioptions,\n",
    "            },\n",
    "            \"smdistributed\": {\n",
    "                \"modelparallel\": {\n",
    "                    \"enabled\":True,\n",
    "                    \"parameters\": {\n",
    "                        \"ddp\": True,\n",
    "                        \"tensor_parallel_degree\": hyperparameters['tensor_parallel_degree'],\n",
    "                        # partitions is a required param in the current SM SDK so it needs to be passed,\n",
    "                        # these two map to the same config\n",
    "                        \"partitions\": hyperparameters['pipeline_parallel_degree'],\n",
    "                        \"shard_optimizer_state\": hyperparameters['shard_optimizer_state'] > 0,\n",
    "                        \"prescaled_batch\": hyperparameters['prescaled_batch'] > 0,\n",
    "                        \"fp16_params\": hyperparameters['fp16'] > 0,\n",
    "                        \"optimize\": hyperparameters['optimize'],\n",
    "                        \"auto_partition\": True,\n",
    "                        \"default_partition\": 0,                        \n",
    "                        \"fp16_params\": hyperparameters['fp16'] > 0,\n",
    "                        \"optimize\": hyperparameters['optimize'],\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        pytorch_version='1.10',\n",
    "        transformers_version='4.17',\n",
    "        py_version='py38',\n",
    "        output_path=s3_output_bucket,\n",
    "        checkpoint_s3_uri=checkpoint_s3_uri if not use_fsx else None,\n",
    "        checkpoint_local_path=hyperparameters['checkpoint-dir'] if use_fsx else None,\n",
    "        metric_definitions=metric_definitions,\n",
    "        hyperparameters=hyperparameters,\n",
    "        debugger_hook_config=False,\n",
    "        disable_profiler=True,\n",
    "        base_job_name=base_job_name,\n",
    "        **kwargs\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, run the estimator to launch the SageMaker training job of GPT-J model with tensor parallelism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: smp-gptj-6b-p4d24x-tp8-pp2-bs16-2022-04-12-21-00-49-763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-12 21:00:52 Starting - Starting the training job......\n",
      "2022-04-12 21:01:51 Starting - Preparing the instances for training................................................\n",
      "2022-04-12 21:09:50 Downloading - Downloading input data...\n",
      "2022-04-12 21:10:16 Training - Downloading the training image.......................\u001b[35mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[35mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[35m2022-04-12 21:14:25,865 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[35m2022-04-12 21:14:25,945 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[35m2022-04-12 21:14:25,952 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-04-12 21:14:25,884 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-04-12 21:14:25,962 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-04-12 21:14:25,968 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-04-12 21:14:26,473 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[35m2022-04-12 21:14:26,491 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[35m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: datasets in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.18.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (1.22.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sagemaker in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (2.77.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sagemaker-experiments in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (0.1.35)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (1.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torchnet in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (0.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: smdebug in /opt/conda/lib/python3.8/site-packages/smdebug-1.0.13b20220304-py3.8.egg (from -r requirements.txt (line 7)) (1.0.13b20220304)\u001b[0m\n",
      "\u001b[34mCollecting humanize\u001b[0m\n",
      "\u001b[34mDownloading humanize-4.0.0-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.7/97.7 KB 3.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (0.18.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (7.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: xxhash in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (3.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (0.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (2.27.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (21.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (1.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (2022.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (3.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (0.70.12.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (4.62.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (0.3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: boto3>=1.20.21 in /opt/conda/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 3)) (1.21.13)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pathos in /opt/conda/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 3)) (0.2.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: google-pasta in /opt/conda/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 3)) (0.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.1 in /opt/conda/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 3)) (3.19.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 3)) (1.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs==20.3.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 3)) (20.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf3-to-dict>=0.1.5 in /opt/conda/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 3)) (0.1.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 3)) (4.11.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from torchnet->-r requirements.txt (line 6)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: visdom in /opt/conda/lib/python3.8/site-packages (from torchnet->-r requirements.txt (line 6)) (0.1.8.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (from torchnet->-r requirements.txt (line 6)) (1.10.2+cu113)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyinstrument==3.4.2 in /opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg (from smdebug->-r requirements.txt (line 7)) (3.4.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyinstrument-cext>=0.2.2 in /opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg (from pyinstrument==3.4.2->smdebug->-r requirements.txt (line 7)) (0.2.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from boto3>=1.20.21->sagemaker->-r requirements.txt (line 3)) (0.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from boto3>=1.20.21->sagemaker->-r requirements.txt (line 3)) (0.5.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: botocore<1.25.0,>=1.24.13 in /opt/conda/lib/python3.8/site-packages (from boto3>=1.20.21->sagemaker->-r requirements.txt (line 3)) (1.24.13)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets->-r requirements.txt (line 1)) (4.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets->-r requirements.txt (line 1)) (3.6.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=1.4.0->sagemaker->-r requirements.txt (line 3)) (3.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->datasets->-r requirements.txt (line 1)) (3.0.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 1)) (3.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 1)) (2021.10.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 1)) (2.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 1)) (1.26.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (6.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (4.0.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.7.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets->-r requirements.txt (line 1)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets->-r requirements.txt (line 1)) (2021.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pox>=0.3.0 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker->-r requirements.txt (line 3)) (0.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ppft>=1.6.6.4 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker->-r requirements.txt (line 3)) (1.6.6.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyzmq in /opt/conda/lib/python3.8/site-packages (from visdom->torchnet->-r requirements.txt (line 6)) (22.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torchfile in /opt/conda/lib/python3.8/site-packages (from visdom->torchnet->-r requirements.txt (line 6)) (0.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jsonpatch in /opt/conda/lib/python3.8/site-packages (from visdom->torchnet->-r requirements.txt (line 6)) (1.32)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tornado in /opt/conda/lib/python3.8/site-packages (from visdom->torchnet->-r requirements.txt (line 6)) (6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow in /opt/conda/lib/python3.8/site-packages (from visdom->torchnet->-r requirements.txt (line 6)) (9.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: websocket-client in /opt/conda/lib/python3.8/site-packages (from visdom->torchnet->-r requirements.txt (line 6)) (1.3.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: datasets in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.18.4)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (1.22.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: sagemaker in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (2.77.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: sagemaker-experiments in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 4)) (0.1.35)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (1.8.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: torchnet in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 6)) (0.0.4)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: smdebug in /opt/conda/lib/python3.8/site-packages/smdebug-1.0.13b20220304-py3.8.egg (from -r requirements.txt (line 7)) (1.0.13b20220304)\u001b[0m\n",
      "\u001b[35mCollecting humanize\u001b[0m\n",
      "\u001b[35mDownloading humanize-4.0.0-py3-none-any.whl (97 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.7/97.7 KB 3.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (4.62.3)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (7.0.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (2.27.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (0.4.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (2022.2.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: dill in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (0.3.4)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (0.70.12.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (0.18.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: xxhash in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (3.0.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (3.8.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (21.3)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets->-r requirements.txt (line 1)) (1.4.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pathos in /opt/conda/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 3)) (0.2.8)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: attrs==20.3.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 3)) (20.3.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: importlib-metadata>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 3)) (4.11.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: boto3>=1.20.21 in /opt/conda/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 3)) (1.21.13)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: google-pasta in /opt/conda/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 3)) (0.2.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: protobuf>=3.1 in /opt/conda/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 3)) (3.19.4)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: protobuf3-to-dict>=0.1.5 in /opt/conda/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 3)) (0.1.5)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.8/site-packages (from sagemaker->-r requirements.txt (line 3)) (1.0.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from torchnet->-r requirements.txt (line 6)) (1.16.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (from torchnet->-r requirements.txt (line 6)) (1.10.2+cu113)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: visdom in /opt/conda/lib/python3.8/site-packages (from torchnet->-r requirements.txt (line 6)) (0.1.8.9)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pyinstrument==3.4.2 in /opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg (from smdebug->-r requirements.txt (line 7)) (3.4.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pyinstrument-cext>=0.2.2 in /opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg (from pyinstrument==3.4.2->smdebug->-r requirements.txt (line 7)) (0.2.4)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from boto3>=1.20.21->sagemaker->-r requirements.txt (line 3)) (0.10.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from boto3>=1.20.21->sagemaker->-r requirements.txt (line 3)) (0.5.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: botocore<1.25.0,>=1.24.13 in /opt/conda/lib/python3.8/site-packages (from boto3>=1.20.21->sagemaker->-r requirements.txt (line 3)) (1.24.13)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets->-r requirements.txt (line 1)) (4.1.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets->-r requirements.txt (line 1)) (5.4.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets->-r requirements.txt (line 1)) (3.6.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=1.4.0->sagemaker->-r requirements.txt (line 3)) (3.7.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->datasets->-r requirements.txt (line 1)) (3.0.7)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 1)) (1.26.7)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 1)) (3.3)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 1)) (2021.10.8)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets->-r requirements.txt (line 1)) (2.0.4)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.7.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.2.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (6.0.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (4.0.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets->-r requirements.txt (line 1)) (1.3.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets->-r requirements.txt (line 1)) (2.8.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets->-r requirements.txt (line 1)) (2021.3)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pox>=0.3.0 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker->-r requirements.txt (line 3)) (0.3.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: ppft>=1.6.6.4 in /opt/conda/lib/python3.8/site-packages (from pathos->sagemaker->-r requirements.txt (line 3)) (1.6.6.4)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: jsonpatch in /opt/conda/lib/python3.8/site-packages (from visdom->torchnet->-r requirements.txt (line 6)) (1.32)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pyzmq in /opt/conda/lib/python3.8/site-packages (from visdom->torchnet->-r requirements.txt (line 6)) (22.3.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: websocket-client in /opt/conda/lib/python3.8/site-packages (from visdom->torchnet->-r requirements.txt (line 6)) (1.3.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pillow in /opt/conda/lib/python3.8/site-packages (from visdom->torchnet->-r requirements.txt (line 6)) (9.0.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: tornado in /opt/conda/lib/python3.8/site-packages (from visdom->torchnet->-r requirements.txt (line 6)) (6.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: torchfile in /opt/conda/lib/python3.8/site-packages (from visdom->torchnet->-r requirements.txt (line 6)) (0.1.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.8/site-packages (from jsonpatch->visdom->torchnet->-r requirements.txt (line 6)) (2.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.8/site-packages (from jsonpatch->visdom->torchnet->-r requirements.txt (line 6)) (2.2)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: humanize\u001b[0m\n",
      "\u001b[34mSuccessfully installed humanize-4.0.0\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[35mInstalling collected packages: humanize\u001b[0m\n",
      "\u001b[35mSuccessfully installed humanize-4.0.0\u001b[0m\n",
      "\u001b[35mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[35m2022-04-12 21:14:28,955 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\u001b[0m\n",
      "\u001b[35m2022-04-12 21:14:28,955 sagemaker-training-toolkit INFO     Waiting for MPI Master to create SSH daemon.\u001b[0m\n",
      "\u001b[35m2022-04-12 21:14:28,958 sagemaker-training-toolkit INFO     Cannot connect to host algo-1\u001b[0m\n",
      "\u001b[35m2022-04-12 21:14:28,958 sagemaker-training-toolkit INFO     Connection failed with exception: \n",
      " [Errno None] Unable to connect to port 22 on 10.0.253.219\u001b[0m\n",
      "\u001b[34m2022-04-12 21:14:29,059 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\u001b[0m\n",
      "\u001b[34m2022-04-12 21:14:29,059 sagemaker-training-toolkit INFO     Creating SSH daemon.\u001b[0m\n",
      "\u001b[34m2022-04-12 21:14:29,064 sagemaker-training-toolkit INFO     Waiting for MPI workers to establish their SSH connections\u001b[0m\n",
      "\u001b[34m2022-04-12 21:14:29,066 sagemaker-training-toolkit INFO     Cannot connect to host algo-2\u001b[0m\n",
      "\u001b[34m2022-04-12 21:14:29,066 sagemaker-training-toolkit INFO     Connection failed with exception: \n",
      " [Errno None] Unable to connect to port 22 on 10.0.242.189\u001b[0m\n",
      "\u001b[35m2022-04-12 21:14:29,969 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_8.2p1)\u001b[0m\n",
      "\u001b[35m2022-04-12 21:14:30,071 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[35m2022-04-12 21:14:30,071 sagemaker-training-toolkit INFO     Can connect to host algo-1\u001b[0m\n",
      "\u001b[35m2022-04-12 21:14:30,072 sagemaker-training-toolkit INFO     MPI Master online, creating SSH daemon.\u001b[0m\n",
      "\u001b[35m2022-04-12 21:14:30,072 sagemaker-training-toolkit INFO     Writing environment variables to /etc/environment for the MPI process.\u001b[0m\n",
      "\u001b[35m2022-04-12 21:14:30,075 sagemaker-training-toolkit INFO     Waiting for MPI process to finish.\u001b[0m\n",
      "\u001b[34m2022-04-12 21:14:30,067 sagemaker-training-toolkit INFO     Cannot connect to host algo-2\u001b[0m\n",
      "\u001b[34m2022-04-12 21:14:30,068 sagemaker-training-toolkit INFO     Connection failed with exception: \n",
      " [Errno None] Unable to connect to port 22 on 10.0.242.189\u001b[0m\n",
      "\u001b[34m2022-04-12 21:14:31,078 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_8.2p1)\u001b[0m\n",
      "\u001b[34m2022-04-12 21:14:31,167 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[34m2022-04-12 21:14:31,168 sagemaker-training-toolkit INFO     Can connect to host algo-2\u001b[0m\n",
      "\u001b[34m2022-04-12 21:14:31,168 sagemaker-training-toolkit INFO     Worker algo-2 available for communication\u001b[0m\n",
      "\u001b[34m2022-04-12 21:14:31,168 sagemaker-training-toolkit INFO     Env Hosts: ['algo-1', 'algo-2'] Hosts: ['algo-1:8', 'algo-2:8'] process_per_hosts: 8 num_processes: 16\u001b[0m\n",
      "\u001b[34m2022-04-12 21:14:31,169 sagemaker-training-toolkit INFO     Network interface name: eth0\u001b[0m\n",
      "\u001b[34m2022-04-12 21:14:31,270 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_distributed_dataparallel_enabled\": false,\n",
      "        \"sagemaker_instance_type\": \"ml.p4d.24xlarge\",\n",
      "        \"sagemaker_mpi_custom_mpi_options\": \"-x NCCL_DEBUG=WARN -x SMDEBUG_LOG_LEVEL=ERROR -x SMP_DISABLE_D2D=1 -x SMP_D2D_GPU_BUFFER_SIZE_BYTES=1 -x SMP_NCCL_THROTTLE_LIMIT=1 -x FI_EFA_USE_DEVICE_RDMA=1 -x FI_PROVIDER=efa -x RDMAV_FORK_SAFE=1\",\n",
      "        \"sagemaker_mpi_enabled\": true,\n",
      "        \"sagemaker_mpi_num_of_processes_per_host\": 8\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"activation_checkpointing\": 1,\n",
      "        \"activation_strategy\": \"each\",\n",
      "        \"checkpoint_freq\": 200,\n",
      "        \"fp16\": 1,\n",
      "        \"hidden_width\": 4096,\n",
      "        \"logging_freq\": 10,\n",
      "        \"lr\": 0.0002,\n",
      "        \"lr-decay-style\": \"linear\",\n",
      "        \"lr_decay_iters\": 125000,\n",
      "        \"max_context_width\": 512,\n",
      "        \"max_steps\": 100,\n",
      "        \"min_lr\": 1e-05,\n",
      "        \"mp_parameters\": {\n",
      "            \"ddp\": true,\n",
      "            \"tensor_parallel_degree\": 8,\n",
      "            \"partitions\": 2,\n",
      "            \"shard_optimizer_state\": true,\n",
      "            \"prescaled_batch\": true,\n",
      "            \"fp16_params\": true,\n",
      "            \"optimize\": \"speed\",\n",
      "            \"auto_partition\": true,\n",
      "            \"default_partition\": 0\n",
      "        },\n",
      "        \"num_heads\": 16,\n",
      "        \"num_kept_checkpoints\": 5,\n",
      "        \"num_layers\": 28,\n",
      "        \"optimize\": \"speed\",\n",
      "        \"pipeline_parallel_degree\": 2,\n",
      "        \"prescaled_batch\": 1,\n",
      "        \"save_final_full_model\": 1,\n",
      "        \"seed\": 12345,\n",
      "        \"shard_optimizer_state\": 1,\n",
      "        \"skip_full_optimizer\": 1,\n",
      "        \"tensor_parallel_degree\": 8,\n",
      "        \"train_batch_size\": 16,\n",
      "        \"val_batch_size\": 16,\n",
      "        \"validation_freq\": 1000,\n",
      "        \"warmup\": 0.01\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"smp-gptj-6b-p4d24x-tp8-pp2-bs16-2022-04-12-21-00-49-763\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-855988369404/smp-gptj-6b-p4d24x-tp8-pp2-bs16-2022-04-12-21-00-49-763/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_gptj_simple\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 96,\n",
      "    \"num_gpus\": 8,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p4d.24xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p4d.24xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-2\",\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_gptj_simple.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"activation_checkpointing\":1,\"activation_strategy\":\"each\",\"checkpoint_freq\":200,\"fp16\":1,\"hidden_width\":4096,\"logging_freq\":10,\"lr\":0.0002,\"lr-decay-style\":\"linear\",\"lr_decay_iters\":125000,\"max_context_width\":512,\"max_steps\":100,\"min_lr\":1e-05,\"mp_parameters\":{\"auto_partition\":true,\"ddp\":true,\"default_partition\":0,\"fp16_params\":true,\"optimize\":\"speed\",\"partitions\":2,\"prescaled_batch\":true,\"shard_optimizer_state\":true,\"tensor_parallel_degree\":8},\"num_heads\":16,\"num_kept_checkpoints\":5,\"num_layers\":28,\"optimize\":\"speed\",\"pipeline_parallel_degree\":2,\"prescaled_batch\":1,\"save_final_full_model\":1,\"seed\":12345,\"shard_optimizer_state\":1,\"skip_full_optimizer\":1,\"tensor_parallel_degree\":8,\"train_batch_size\":16,\"val_batch_size\":16,\"validation_freq\":1000,\"warmup\":0.01}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_gptj_simple.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_distributed_dataparallel_enabled\":false,\"sagemaker_instance_type\":\"ml.p4d.24xlarge\",\"sagemaker_mpi_custom_mpi_options\":\"-x NCCL_DEBUG=WARN -x SMDEBUG_LOG_LEVEL=ERROR -x SMP_DISABLE_D2D=1 -x SMP_D2D_GPU_BUFFER_SIZE_BYTES=1 -x SMP_NCCL_THROTTLE_LIMIT=1 -x FI_EFA_USE_DEVICE_RDMA=1 -x FI_PROVIDER=efa -x RDMAV_FORK_SAFE=1\",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":8}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p4d.24xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-2\",\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4d.24xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_gptj_simple\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=96\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-855988369404/smp-gptj-6b-p4d24x-tp8-pp2-bs16-2022-04-12-21-00-49-763/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_distributed_dataparallel_enabled\":false,\"sagemaker_instance_type\":\"ml.p4d.24xlarge\",\"sagemaker_mpi_custom_mpi_options\":\"-x NCCL_DEBUG=WARN -x SMDEBUG_LOG_LEVEL=ERROR -x SMP_DISABLE_D2D=1 -x SMP_D2D_GPU_BUFFER_SIZE_BYTES=1 -x SMP_NCCL_THROTTLE_LIMIT=1 -x FI_EFA_USE_DEVICE_RDMA=1 -x FI_PROVIDER=efa -x RDMAV_FORK_SAFE=1\",\"sagemaker_mpi_enabled\":true,\"sagemaker_mpi_num_of_processes_per_host\":8},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"activation_checkpointing\":1,\"activation_strategy\":\"each\",\"checkpoint_freq\":200,\"fp16\":1,\"hidden_width\":4096,\"logging_freq\":10,\"lr\":0.0002,\"lr-decay-style\":\"linear\",\"lr_decay_iters\":125000,\"max_context_width\":512,\"max_steps\":100,\"min_lr\":1e-05,\"mp_parameters\":{\"auto_partition\":true,\"ddp\":true,\"default_partition\":0,\"fp16_params\":true,\"optimize\":\"speed\",\"partitions\":2,\"prescaled_batch\":true,\"shard_optimizer_state\":true,\"tensor_parallel_degree\":8},\"num_heads\":16,\"num_kept_checkpoints\":5,\"num_layers\":28,\"optimize\":\"speed\",\"pipeline_parallel_degree\":2,\"prescaled_batch\":1,\"save_final_full_model\":1,\"seed\":12345,\"shard_optimizer_state\":1,\"skip_full_optimizer\":1,\"tensor_parallel_degree\":8,\"train_batch_size\":16,\"val_batch_size\":16,\"validation_freq\":1000,\"warmup\":0.01},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"smp-gptj-6b-p4d24x-tp8-pp2-bs16-2022-04-12-21-00-49-763\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-855988369404/smp-gptj-6b-p4d24x-tp8-pp2-bs16-2022-04-12-21-00-49-763/source/sourcedir.tar.gz\",\"module_name\":\"train_gptj_simple\",\"network_interface_name\":\"eth0\",\"num_cpus\":96,\"num_gpus\":8,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p4d.24xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-2\",\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p4d.24xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_gptj_simple.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--activation_checkpointing\",\"1\",\"--activation_strategy\",\"each\",\"--checkpoint_freq\",\"200\",\"--fp16\",\"1\",\"--hidden_width\",\"4096\",\"--logging_freq\",\"10\",\"--lr\",\"0.0002\",\"--lr-decay-style\",\"linear\",\"--lr_decay_iters\",\"125000\",\"--max_context_width\",\"512\",\"--max_steps\",\"100\",\"--min_lr\",\"1e-05\",\"--mp_parameters\",\"auto_partition=True,ddp=True,default_partition=0,fp16_params=True,optimize=speed,partitions=2,prescaled_batch=True,shard_optimizer_state=True,tensor_parallel_degree=8\",\"--num_heads\",\"16\",\"--num_kept_checkpoints\",\"5\",\"--num_layers\",\"28\",\"--optimize\",\"speed\",\"--pipeline_parallel_degree\",\"2\",\"--prescaled_batch\",\"1\",\"--save_final_full_model\",\"1\",\"--seed\",\"12345\",\"--shard_optimizer_state\",\"1\",\"--skip_full_optimizer\",\"1\",\"--tensor_parallel_degree\",\"8\",\"--train_batch_size\",\"16\",\"--val_batch_size\",\"16\",\"--validation_freq\",\"1000\",\"--warmup\",\"0.01\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_ACTIVATION_CHECKPOINTING=1\u001b[0m\n",
      "\u001b[34mSM_HP_ACTIVATION_STRATEGY=each\u001b[0m\n",
      "\u001b[34mSM_HP_CHECKPOINT_FREQ=200\u001b[0m\n",
      "\u001b[34mSM_HP_FP16=1\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_WIDTH=4096\u001b[0m\n",
      "\u001b[34mSM_HP_LOGGING_FREQ=10\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.0002\u001b[0m\n",
      "\u001b[34mSM_HP_LR-DECAY-STYLE=linear\u001b[0m\n",
      "\u001b[34mSM_HP_LR_DECAY_ITERS=125000\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_CONTEXT_WIDTH=512\u001b[0m\n",
      "\u001b[34mSM_HP_MAX_STEPS=100\u001b[0m\n",
      "\u001b[34mSM_HP_MIN_LR=1e-05\u001b[0m\n",
      "\u001b[34mSM_HP_MP_PARAMETERS={\"auto_partition\":true,\"ddp\":true,\"default_partition\":0,\"fp16_params\":true,\"optimize\":\"speed\",\"partitions\":2,\"prescaled_batch\":true,\"shard_optimizer_state\":true,\"tensor_parallel_degree\":8}\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_HEADS=16\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_KEPT_CHECKPOINTS=5\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_LAYERS=28\u001b[0m\n",
      "\u001b[34mSM_HP_OPTIMIZE=speed\u001b[0m\n",
      "\u001b[34mSM_HP_PIPELINE_PARALLEL_DEGREE=2\u001b[0m\n",
      "\u001b[34mSM_HP_PRESCALED_BATCH=1\u001b[0m\n",
      "\u001b[34mSM_HP_SAVE_FINAL_FULL_MODEL=1\u001b[0m\n",
      "\u001b[34mSM_HP_SEED=12345\u001b[0m\n",
      "\u001b[34mSM_HP_SHARD_OPTIMIZER_STATE=1\u001b[0m\n",
      "\u001b[34mSM_HP_SKIP_FULL_OPTIMIZER=1\u001b[0m\n",
      "\u001b[34mSM_HP_TENSOR_PARALLEL_DEGREE=8\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_BATCH_SIZE=16\u001b[0m\n",
      "\u001b[34mSM_HP_VAL_BATCH_SIZE=16\u001b[0m\n",
      "\u001b[34mSM_HP_VALIDATION_FREQ=1000\u001b[0m\n",
      "\u001b[34mSM_HP_WARMUP=0.01\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.13b20220304-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg:/opt/conda/lib/python3.8/site-packages/urllib3-1.26.8-py3.8.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34mmpirun --host algo-1:8,algo-2:8 -np 16 --allow-run-as-root --display-map --tag-output -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -bind-to none -map-by slot -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -mca btl_vader_single_copy_mechanism none -x NCCL_MIN_NRINGS=4 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x LD_PRELOAD=/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so -x NCCL_DEBUG=WARN -x SMDEBUG_LOG_LEVEL=ERROR -x SMP_DISABLE_D2D=1 -x SMP_D2D_GPU_BUFFER_SIZE_BYTES=1 -x SMP_NCCL_THROTTLE_LIMIT=1 -x FI_EFA_USE_DEVICE_RDMA=1 -x FI_PROVIDER=efa -x RDMAV_FORK_SAFE=1 -x SM_HOSTS -x SM_NETWORK_INTERFACE_NAME -x SM_HPS -x SM_USER_ENTRY_POINT -x SM_FRAMEWORK_PARAMS -x SM_RESOURCE_CONFIG -x SM_INPUT_DATA_CONFIG -x SM_OUTPUT_DATA_DIR -x SM_CHANNELS -x SM_CURRENT_HOST -x SM_MODULE_NAME -x SM_LOG_LEVEL -x SM_FRAMEWORK_MODULE -x SM_INPUT_DIR -x SM_INPUT_CONFIG_DIR -x SM_OUTPUT_DIR -x SM_NUM_CPUS -x SM_NUM_GPUS -x SM_MODEL_DIR -x SM_MODULE_DIR -x SM_TRAINING_ENV -x SM_USER_ARGS -x SM_OUTPUT_INTERMEDIATE_DIR -x SM_CHANNEL_TEST -x SM_CHANNEL_TRAIN -x SM_HP_ACTIVATION_CHECKPOINTING -x SM_HP_ACTIVATION_STRATEGY -x SM_HP_CHECKPOINT_FREQ -x SM_HP_FP16 -x SM_HP_HIDDEN_WIDTH -x SM_HP_LOGGING_FREQ -x SM_HP_LR -x SM_HP_LR-DECAY-STYLE -x SM_HP_LR_DECAY_ITERS -x SM_HP_MAX_CONTEXT_WIDTH -x SM_HP_MAX_STEPS -x SM_HP_MIN_LR -x SM_HP_MP_PARAMETERS -x SM_HP_NUM_HEADS -x SM_HP_NUM_KEPT_CHECKPOINTS -x SM_HP_NUM_LAYERS -x SM_HP_OPTIMIZE -x SM_HP_PIPELINE_PARALLEL_DEGREE -x SM_HP_PRESCALED_BATCH -x SM_HP_SAVE_FINAL_FULL_MODEL -x SM_HP_SEED -x SM_HP_SHARD_OPTIMIZER_STATE -x SM_HP_SKIP_FULL_OPTIMIZER -x SM_HP_TENSOR_PARALLEL_DEGREE -x SM_HP_TRAIN_BATCH_SIZE -x SM_HP_VAL_BATCH_SIZE -x SM_HP_VALIDATION_FREQ -x SM_HP_WARMUP -x PYTHONPATH /opt/conda/bin/python3.8 -m mpi4py train_gptj_simple.py --activation_checkpointing 1 --activation_strategy each --checkpoint_freq 200 --fp16 1 --hidden_width 4096 --logging_freq 10 --lr 0.0002 --lr-decay-style linear --lr_decay_iters 125000 --max_context_width 512 --max_steps 100 --min_lr 1e-05 --mp_parameters auto_partition=True,ddp=True,default_partition=0,fp16_params=True,optimize=speed,partitions=2,prescaled_batch=True,shard_optimizer_state=True,tensor_parallel_degree=8 --num_heads 16 --num_kept_checkpoints 5 --num_layers 28 --optimize speed --pipeline_parallel_degree 2 --prescaled_batch 1 --save_final_full_model 1 --seed 12345 --shard_optimizer_state 1 --skip_full_optimizer 1 --tensor_parallel_degree 8 --train_batch_size 16 --val_batch_size 16 --validation_freq 1000 --warmup 0.01\u001b[0m\n",
      "\u001b[34m[algo-1:00048] Warning: could not find environment variable \"SM_HP_LR-DECAY-STYLE\"\u001b[0m\n",
      "\u001b[34mWarning: Permanently added 'algo-2,10.0.242.189' (ECDSA) to the list of known hosts.\u001b[0m\n",
      "\u001b[34mData for JOB [41174,1] offset 0 Total slots allocated 16\n",
      " ========================   JOB MAP   ========================\n",
      " Data for node: algo-1#011Num slots: 8#011Max slots: 0#011Num procs: 8\n",
      " #011Process OMPI jobid: [41174,1] App: 0 Process rank: 0 Bound: N/A\n",
      " #011Process OMPI jobid: [41174,1] App: 0 Process rank: 1 Bound: N/A\n",
      " #011Process OMPI jobid: [41174,1] App: 0 Process rank: 2 Bound: N/A\n",
      " #011Process OMPI jobid: [41174,1] App: 0 Process rank: 3 Bound: N/A\n",
      " #011Process OMPI jobid: [41174,1] App: 0 Process rank: 4 Bound: N/A\n",
      " #011Process OMPI jobid: [41174,1] App: 0 Process rank: 5 Bound: N/A\n",
      " #011Process OMPI jobid: [41174,1] App: 0 Process rank: 6 Bound: N/A\n",
      " #011Process OMPI jobid: [41174,1] App: 0 Process rank: 7 Bound: N/A\n",
      " Data for node: algo-2#011Num slots: 8#011Max slots: 0#011Num procs: 8\n",
      " #011Process OMPI jobid: [41174,1] App: 0 Process rank: 8 Bound: N/A\n",
      " #011Process OMPI jobid: [41174,1] App: 0 Process rank: 9 Bound: N/A\n",
      " #011Process OMPI jobid: [41174,1] App: 0 Process rank: 10 Bound: N/A\n",
      " #011Process OMPI jobid: [41174,1] App: 0 Process rank: 11 Bound: N/A\n",
      " #011Process OMPI jobid: [41174,1] App: 0 Process rank: 12 Bound: N/A\n",
      " #011Process OMPI jobid: [41174,1] App: 0 Process rank: 13 Bound: N/A\n",
      " #011Process OMPI jobid: [41174,1] App: 0 Process rank: 14 Bound: N/A\n",
      " #011Process OMPI jobid: [41174,1] App: 0 Process rank: 15 Bound: N/A\n",
      " =============================================================\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m2022-04-12 21:14:32,079 sagemaker-training-toolkit INFO     Process[es]: [psutil.Process(pid=57, name='orted', status='sleeping', started='21:14:31')]\u001b[0m\n",
      "\u001b[35m2022-04-12 21:14:32,080 sagemaker-training-toolkit INFO     Orted process found [psutil.Process(pid=57, name='orted', status='sleeping', started='21:14:31')]\u001b[0m\n",
      "\u001b[35m2022-04-12 21:14:32,080 sagemaker-training-toolkit INFO     Waiting for orted process [psutil.Process(pid=57, name='orted', status='sleeping', started='21:14:31')]\u001b[0m\n",
      "\n",
      "2022-04-12 21:14:23 Training - Training image download completed. Training in progress.\u001b[34m[1,mpirank:8,algo-2]<stderr>:Environment variable SAGEMAKER_INSTANCE_TYPE is not set\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:Environment variable SAGEMAKER_INSTANCE_TYPE is not set\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:Environment variable SAGEMAKER_INSTANCE_TYPE is not set\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:Environment variable SAGEMAKER_INSTANCE_TYPE is not set\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:Environment variable SAGEMAKER_INSTANCE_TYPE is not set\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:Environment variable SAGEMAKER_INSTANCE_TYPE is not set\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:Environment variable SAGEMAKER_INSTANCE_TYPE is not set\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:Environment variable SAGEMAKER_INSTANCE_TYPE is not set\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:Environment variable SAGEMAKER_INSTANCE_TYPE is not set\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:Environment variable SAGEMAKER_INSTANCE_TYPE is not set\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:Environment variable SAGEMAKER_INSTANCE_TYPE is not set\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:Environment variable SAGEMAKER_INSTANCE_TYPE is not set\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:Environment variable SAGEMAKER_INSTANCE_TYPE is not set\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:Environment variable SAGEMAKER_INSTANCE_TYPE is not set\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:Environment variable SAGEMAKER_INSTANCE_TYPE is not set\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:Environment variable SAGEMAKER_INSTANCE_TYPE is not set\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 14\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 13\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 10\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 11\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 9\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 15\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 12\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 8\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:2 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:2 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:2 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:2 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:2 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:2 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:2 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:2 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 12: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 8: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:2 to store for rank: 12\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:2 to store for rank: 8\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 10: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 13: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 14: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:2 to store for rank: 10\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 11: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 9: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:2 to store for rank: 13\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 15: Completed store-based barrier for key:store_based_barrier_key:1 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:2 to store for rank: 14\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:2 to store for rank: 11\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:2 to store for rank: 9\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:2 to store for rank: 15\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 9: Completed store-based barrier for key:store_based_barrier_key:2 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 15: Completed store-based barrier for key:store_based_barrier_key:2 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:3 to store for rank: 9\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:3 to store for rank: 15\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:3 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:2 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:2 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:2 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:2 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:2 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:2 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:2 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:3 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:3 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:3 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:3 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:3 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:3 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:3 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 12: Completed store-based barrier for key:store_based_barrier_key:2 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 8: Completed store-based barrier for key:store_based_barrier_key:2 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:3 to store for rank: 12\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:3 to store for rank: 8\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 10: Completed store-based barrier for key:store_based_barrier_key:2 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 13: Completed store-based barrier for key:store_based_barrier_key:2 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:3 to store for rank: 10\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 14: Completed store-based barrier for key:store_based_barrier_key:2 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:3 to store for rank: 13\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 11: Completed store-based barrier for key:store_based_barrier_key:2 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:3 to store for rank: 14\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:3 to store for rank: 11\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 14: Completed store-based barrier for key:store_based_barrier_key:3 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 11: Completed store-based barrier for key:store_based_barrier_key:3 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 9: Completed store-based barrier for key:store_based_barrier_key:3 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 15: Completed store-based barrier for key:store_based_barrier_key:3 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:3 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:4 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:3 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:3 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:3 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:3 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:3 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:3 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:3 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:4 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:4 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:4 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:4 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:4 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:4 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:4 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 8: Completed store-based barrier for key:store_based_barrier_key:3 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 12: Completed store-based barrier for key:store_based_barrier_key:3 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:4 to store for rank: 8\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:4 to store for rank: 12\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:4 to store for rank: 14\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:4 to store for rank: 15\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:4 to store for rank: 11\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:4 to store for rank: 9\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 10: Completed store-based barrier for key:store_based_barrier_key:3 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 13: Completed store-based barrier for key:store_based_barrier_key:3 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:4 to store for rank: 10\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:4 to store for rank: 13\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 13: Completed store-based barrier for key:store_based_barrier_key:4 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:4 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:5 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:5 to store for rank: 13\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:4 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:4 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:4 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:4 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:4 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:4 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:4 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:5 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:5 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:5 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:5 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:5 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:5 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:5 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 11: Completed store-based barrier for key:store_based_barrier_key:4 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 8: Completed store-based barrier for key:store_based_barrier_key:4 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 15: Completed store-based barrier for key:store_based_barrier_key:4 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 12: Completed store-based barrier for key:store_based_barrier_key:4 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 14: Completed store-based barrier for key:store_based_barrier_key:4 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 9: Completed store-based barrier for key:store_based_barrier_key:4 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:5 to store for rank: 11\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:5 to store for rank: 14\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:5 to store for rank: 8\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:5 to store for rank: 9\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:5 to store for rank: 12\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:5 to store for rank: 15\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 10: Completed store-based barrier for key:store_based_barrier_key:4 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:5 to store for rank: 10\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 10: Completed store-based barrier for key:store_based_barrier_key:5 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:6 to store for rank: 10\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:5 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:6 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 13: Completed store-based barrier for key:store_based_barrier_key:5 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:6 to store for rank: 13\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:5 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:5 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:6 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:6 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:5 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:5 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:5 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:6 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:5 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:6 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:6 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:5 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:6 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:6 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 14: Completed store-based barrier for key:store_based_barrier_key:5 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 11: Completed store-based barrier for key:store_based_barrier_key:5 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 9: Completed store-based barrier for key:store_based_barrier_key:5 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 8: Completed store-based barrier for key:store_based_barrier_key:5 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 15: Completed store-based barrier for key:store_based_barrier_key:5 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:6 to store for rank: 14\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 12: Completed store-based barrier for key:store_based_barrier_key:5 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:6 to store for rank: 11\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:6 to store for rank: 15\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:6 to store for rank: 12\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:6 to store for rank: 9\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:6 to store for rank: 8\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 8: Completed store-based barrier for key:store_based_barrier_key:6 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:7 to store for rank: 8\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 10: Completed store-based barrier for key:store_based_barrier_key:6 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:7 to store for rank: 10\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:6 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:7 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 13: Completed store-based barrier for key:store_based_barrier_key:6 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:7 to store for rank: 13\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:6 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:6 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:7 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:7 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:6 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:6 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:6 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:7 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:6 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:6 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:7 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:7 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:7 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:7 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 14: Completed store-based barrier for key:store_based_barrier_key:6 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 11: Completed store-based barrier for key:store_based_barrier_key:6 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 15: Completed store-based barrier for key:store_based_barrier_key:6 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:7 to store for rank: 14\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:7 to store for rank: 11\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 12: Completed store-based barrier for key:store_based_barrier_key:6 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 9: Completed store-based barrier for key:store_based_barrier_key:6 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:7 to store for rank: 15\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:7 to store for rank: 12\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:7 to store for rank: 9\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 9: Completed store-based barrier for key:store_based_barrier_key:7 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:8 to store for rank: 9\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 10: Completed store-based barrier for key:store_based_barrier_key:7 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:7 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:8 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:7 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:7 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 13: Completed store-based barrier for key:store_based_barrier_key:7 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:8 to store for rank: 13\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:8 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:8 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:7 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:7 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:7 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:7 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:7 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:8 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:8 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:8 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:8 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:8 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:8 to store for rank: 10\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 11: Completed store-based barrier for key:store_based_barrier_key:7 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 14: Completed store-based barrier for key:store_based_barrier_key:7 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:8 to store for rank: 14\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 15: Completed store-based barrier for key:store_based_barrier_key:7 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:8 to store for rank: 11\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 8: Completed store-based barrier for key:store_based_barrier_key:7 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:8 to store for rank: 15\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 12: Completed store-based barrier for key:store_based_barrier_key:7 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:8 to store for rank: 8\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:8 to store for rank: 12\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 8: Completed store-based barrier for key:store_based_barrier_key:8 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 12: Completed store-based barrier for key:store_based_barrier_key:8 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:9 to store for rank: 8\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 9: Completed store-based barrier for key:store_based_barrier_key:8 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:9 to store for rank: 12\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:9 to store for rank: 9\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:8 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:9 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:8 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:8 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:8 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 13: Completed store-based barrier for key:store_based_barrier_key:8 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:9 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:9 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:9 to store for rank: 13\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:9 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:8 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:8 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:8 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:8 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:9 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:9 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:9 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:9 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 10: Completed store-based barrier for key:store_based_barrier_key:8 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:9 to store for rank: 10\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 15: Completed store-based barrier for key:store_based_barrier_key:8 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 11: Completed store-based barrier for key:store_based_barrier_key:8 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 14: Completed store-based barrier for key:store_based_barrier_key:8 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:9 to store for rank: 14\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:9 to store for rank: 15\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:9 to store for rank: 11\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 8: Completed store-based barrier for key:store_based_barrier_key:9 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 11: Completed store-based barrier for key:store_based_barrier_key:9 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 12: Completed store-based barrier for key:store_based_barrier_key:9 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:10 to store for rank: 8\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 9: Completed store-based barrier for key:store_based_barrier_key:9 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:10 to store for rank: 11\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:10 to store for rank: 9\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:9 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:10 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:9 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:9 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:9 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 13: Completed store-based barrier for key:store_based_barrier_key:9 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:10 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:10 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:9 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:10 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:9 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:10 to store for rank: 13\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:9 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:9 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:10 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:10 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:10 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 10: Completed store-based barrier for key:store_based_barrier_key:9 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:10 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:10 to store for rank: 12\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:10 to store for rank: 10\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 14: Completed store-based barrier for key:store_based_barrier_key:9 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 15: Completed store-based barrier for key:store_based_barrier_key:9 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:10 to store for rank: 14\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:10 to store for rank: 15\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 15: Completed store-based barrier for key:store_based_barrier_key:10 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 14: Completed store-based barrier for key:store_based_barrier_key:10 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:11 to store for rank: 15\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:11 to store for rank: 14\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 8: Completed store-based barrier for key:store_based_barrier_key:10 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 11: Completed store-based barrier for key:store_based_barrier_key:10 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 9: Completed store-based barrier for key:store_based_barrier_key:10 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:11 to store for rank: 11\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:11 to store for rank: 8\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:11 to store for rank: 9\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:10 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:11 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:10 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:10 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:11 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:11 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:10 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:11 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:10 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:10 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:10 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:10 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:11 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 13: Completed store-based barrier for key:store_based_barrier_key:10 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:11 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:11 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:11 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 10: Completed store-based barrier for key:store_based_barrier_key:10 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 12: Completed store-based barrier for key:store_based_barrier_key:10 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:11 to store for rank: 10\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:11 to store for rank: 13\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:11 to store for rank: 12\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 10: Completed store-based barrier for key:store_based_barrier_key:11 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 13: Completed store-based barrier for key:store_based_barrier_key:11 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 12: Completed store-based barrier for key:store_based_barrier_key:11 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:12 to store for rank: 10\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:12 to store for rank: 13\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:12 to store for rank: 12\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 15: Completed store-based barrier for key:store_based_barrier_key:11 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 14: Completed store-based barrier for key:store_based_barrier_key:11 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:12 to store for rank: 15\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 11: Completed store-based barrier for key:store_based_barrier_key:11 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 8: Completed store-based barrier for key:store_based_barrier_key:11 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 9: Completed store-based barrier for key:store_based_barrier_key:11 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:12 to store for rank: 11\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:12 to store for rank: 8\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:12 to store for rank: 9\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:11 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:12 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:11 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:11 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:12 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:12 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:11 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:11 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:12 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:11 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:12 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:11 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:12 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:11 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:12 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:12 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:12 to store for rank: 14\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 14: Completed store-based barrier for key:store_based_barrier_key:12 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:13 to store for rank: 14\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 15: Completed store-based barrier for key:store_based_barrier_key:12 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 8: Completed store-based barrier for key:store_based_barrier_key:12 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 11: Completed store-based barrier for key:store_based_barrier_key:12 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 9: Completed store-based barrier for key:store_based_barrier_key:12 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:13 to store for rank: 8\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:13 to store for rank: 11\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:13 to store for rank: 9\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:12 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:13 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:12 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:12 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:13 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:13 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:12 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:12 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:12 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:13 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:12 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:13 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:13 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:12 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:13 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:13 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 10: Completed store-based barrier for key:store_based_barrier_key:12 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 13: Completed store-based barrier for key:store_based_barrier_key:12 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 12: Completed store-based barrier for key:store_based_barrier_key:12 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:13 to store for rank: 15\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:13 to store for rank: 13\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:13 to store for rank: 10\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:13 to store for rank: 12\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 15: Completed store-based barrier for key:store_based_barrier_key:13 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 13: Completed store-based barrier for key:store_based_barrier_key:13 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 10: Completed store-based barrier for key:store_based_barrier_key:13 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 12: Completed store-based barrier for key:store_based_barrier_key:13 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:14 to store for rank: 13\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:14 to store for rank: 10\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:14 to store for rank: 15\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:14 to store for rank: 12\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 8: Completed store-based barrier for key:store_based_barrier_key:13 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 11: Completed store-based barrier for key:store_based_barrier_key:13 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 9: Completed store-based barrier for key:store_based_barrier_key:13 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:14 to store for rank: 8\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:14 to store for rank: 11\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:14 to store for rank: 9\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:13 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:14 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:13 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:13 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:13 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:14 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:13 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:14 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:13 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:13 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:14 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:13 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:14 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:14 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:14 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:14 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 14: Completed store-based barrier for key:store_based_barrier_key:13 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:14 to store for rank: 14\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 14: Completed store-based barrier for key:store_based_barrier_key:14 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 10: Completed store-based barrier for key:store_based_barrier_key:14 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 13: Completed store-based barrier for key:store_based_barrier_key:14 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 15: Completed store-based barrier for key:store_based_barrier_key:14 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 12: Completed store-based barrier for key:store_based_barrier_key:14 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 11: Completed store-based barrier for key:store_based_barrier_key:14 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 8: Completed store-based barrier for key:store_based_barrier_key:14 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 9: Completed store-based barrier for key:store_based_barrier_key:14 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:15 to store for rank: 8\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:15 to store for rank: 11\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:15 to store for rank: 9\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:15 to store for rank: 13\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:15 to store for rank: 14\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:15 to store for rank: 10\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:15 to store for rank: 12\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:15 to store for rank: 15\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:14 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:15 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:14 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:14 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:15 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:15 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:14 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:15 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:14 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:14 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:14 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:14 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:15 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:15 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:15 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:15 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:15 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:15 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:16 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:16 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 8: Completed store-based barrier for key:store_based_barrier_key:15 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 11: Completed store-based barrier for key:store_based_barrier_key:15 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 9: Completed store-based barrier for key:store_based_barrier_key:15 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:16 to store for rank: 8\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 15: Completed store-based barrier for key:store_based_barrier_key:15 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 10: Completed store-based barrier for key:store_based_barrier_key:15 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:16 to store for rank: 11\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:16 to store for rank: 9\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 13: Completed store-based barrier for key:store_based_barrier_key:15 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 14: Completed store-based barrier for key:store_based_barrier_key:15 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:16 to store for rank: 10\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 12: Completed store-based barrier for key:store_based_barrier_key:15 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:16 to store for rank: 15\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:16 to store for rank: 13\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:16 to store for rank: 14\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:16 to store for rank: 12\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:15 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:16 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:15 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:15 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:16 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:16 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:15 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:16 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:15 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:15 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:16 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:16 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:16 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:16 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:16 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:17 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:17 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:16 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:17 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:17 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 8: Completed store-based barrier for key:store_based_barrier_key:16 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 11: Completed store-based barrier for key:store_based_barrier_key:16 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:17 to store for rank: 8\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 9: Completed store-based barrier for key:store_based_barrier_key:16 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 15: Completed store-based barrier for key:store_based_barrier_key:16 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:17 to store for rank: 11\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:17 to store for rank: 9\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 10: Completed store-based barrier for key:store_based_barrier_key:16 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:17 to store for rank: 15\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 14: Completed store-based barrier for key:store_based_barrier_key:16 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 13: Completed store-based barrier for key:store_based_barrier_key:16 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 12: Completed store-based barrier for key:store_based_barrier_key:16 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:17 to store for rank: 10\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:17 to store for rank: 13\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:17 to store for rank: 14\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:17 to store for rank: 12\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:16 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:17 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:16 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:17 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:16 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:16 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:17 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:17 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:17 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:17 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:18 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:18 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:17 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:17 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:17 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:18 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:17 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:18 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:18 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:18 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 8: Completed store-based barrier for key:store_based_barrier_key:17 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 9: Completed store-based barrier for key:store_based_barrier_key:17 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 11: Completed store-based barrier for key:store_based_barrier_key:17 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:18 to store for rank: 8\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 15: Completed store-based barrier for key:store_based_barrier_key:17 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:18 to store for rank: 11\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:18 to store for rank: 9\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 10: Completed store-based barrier for key:store_based_barrier_key:17 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:18 to store for rank: 15\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 14: Completed store-based barrier for key:store_based_barrier_key:17 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:18 to store for rank: 10\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 12: Completed store-based barrier for key:store_based_barrier_key:17 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 13: Completed store-based barrier for key:store_based_barrier_key:17 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:18 to store for rank: 14\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:18 to store for rank: 12\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:17 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:18 to store for rank: 13\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:18 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:17 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:18 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:18 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:18 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:19 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:19 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:18 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:19 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:18 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:18 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:18 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:19 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:18 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:19 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:19 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:19 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 8: Completed store-based barrier for key:store_based_barrier_key:18 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:19 to store for rank: 8\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 9: Completed store-based barrier for key:store_based_barrier_key:18 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 15: Completed store-based barrier for key:store_based_barrier_key:18 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 11: Completed store-based barrier for key:store_based_barrier_key:18 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:19 to store for rank: 9\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 10: Completed store-based barrier for key:store_based_barrier_key:18 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:19 to store for rank: 15\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:18 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 14: Completed store-based barrier for key:store_based_barrier_key:18 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:19 to store for rank: 10\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 13: Completed store-based barrier for key:store_based_barrier_key:18 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:19 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:19 to store for rank: 11\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 12: Completed store-based barrier for key:store_based_barrier_key:18 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:19 to store for rank: 14\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:19 to store for rank: 13\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:19 to store for rank: 12\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 13: Completed store-based barrier for key:store_based_barrier_key:19 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 12: Completed store-based barrier for key:store_based_barrier_key:19 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:20 to store for rank: 13\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:20 to store for rank: 12\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:19 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:19 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:20 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:19 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:20 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:20 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:19 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:19 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:19 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:19 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:20 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:20 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:20 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:20 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 8: Completed store-based barrier for key:store_based_barrier_key:19 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 9: Completed store-based barrier for key:store_based_barrier_key:19 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:19 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 15: Completed store-based barrier for key:store_based_barrier_key:19 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:20 to store for rank: 8\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:20 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 10: Completed store-based barrier for key:store_based_barrier_key:19 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:20 to store for rank: 9\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:20 to store for rank: 15\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 11: Completed store-based barrier for key:store_based_barrier_key:19 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 14: Completed store-based barrier for key:store_based_barrier_key:19 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:20 to store for rank: 10\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:20 to store for rank: 11\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:20 to store for rank: 14\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 10: Completed store-based barrier for key:store_based_barrier_key:20 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 14: Completed store-based barrier for key:store_based_barrier_key:20 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 11: Completed store-based barrier for key:store_based_barrier_key:20 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 13: Completed store-based barrier for key:store_based_barrier_key:20 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 12: Completed store-based barrier for key:store_based_barrier_key:20 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:21 to store for rank: 10\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:21 to store for rank: 14\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:21 to store for rank: 13\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:21 to store for rank: 11\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:21 to store for rank: 12\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:20 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:20 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:21 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:21 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:20 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:21 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:20 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:20 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:21 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:20 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:21 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:20 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:21 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:21 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:20 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:21 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 8: Completed store-based barrier for key:store_based_barrier_key:20 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 9: Completed store-based barrier for key:store_based_barrier_key:20 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:21 to store for rank: 8\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 15: Completed store-based barrier for key:store_based_barrier_key:20 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:21 to store for rank: 9\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:21 to store for rank: 15\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 9: Completed store-based barrier for key:store_based_barrier_key:21 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 14: Completed store-based barrier for key:store_based_barrier_key:21 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 10: Completed store-based barrier for key:store_based_barrier_key:21 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 15: Completed store-based barrier for key:store_based_barrier_key:21 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 11: Completed store-based barrier for key:store_based_barrier_key:21 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 12: Completed store-based barrier for key:store_based_barrier_key:21 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:22 to store for rank: 9\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:22 to store for rank: 14\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:22 to store for rank: 10\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 13: Completed store-based barrier for key:store_based_barrier_key:21 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:22 to store for rank: 11\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:22 to store for rank: 15\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:22 to store for rank: 12\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:22 to store for rank: 13\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:21 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:22 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:21 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:22 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:21 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:22 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:21 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:21 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:22 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:22 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:21 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:21 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:22 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:22 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:21 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:22 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 8: Completed store-based barrier for key:store_based_barrier_key:21 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:22 to store for rank: 8\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 8: Completed store-based barrier for key:store_based_barrier_key:22 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 9: Completed store-based barrier for key:store_based_barrier_key:22 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 15: Completed store-based barrier for key:store_based_barrier_key:22 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:23 to store for rank: 8\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 14: Completed store-based barrier for key:store_based_barrier_key:22 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:23 to store for rank: 9\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 10: Completed store-based barrier for key:store_based_barrier_key:22 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 11: Completed store-based barrier for key:store_based_barrier_key:22 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:23 to store for rank: 15\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:23 to store for rank: 14\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 12: Completed store-based barrier for key:store_based_barrier_key:22 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 13: Completed store-based barrier for key:store_based_barrier_key:22 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:23 to store for rank: 10\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:23 to store for rank: 11\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:23 to store for rank: 13\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:23 to store for rank: 12\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:22 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:23 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:22 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:23 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:22 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:23 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:22 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:22 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:23 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:23 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:22 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:22 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:23 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:23 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:22 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:23 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:23 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:24 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 8: Completed store-based barrier for key:store_based_barrier_key:23 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 15: Completed store-based barrier for key:store_based_barrier_key:23 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 9: Completed store-based barrier for key:store_based_barrier_key:23 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 14: Completed store-based barrier for key:store_based_barrier_key:23 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:24 to store for rank: 8\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 10: Completed store-based barrier for key:store_based_barrier_key:23 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:24 to store for rank: 15\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 11: Completed store-based barrier for key:store_based_barrier_key:23 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:24 to store for rank: 14\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:23 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 13: Completed store-based barrier for key:store_based_barrier_key:23 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:24 to store for rank: 10\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:24 to store for rank: 11\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:24 to store for rank: 9\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 12: Completed store-based barrier for key:store_based_barrier_key:23 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:24 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:23 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:24 to store for rank: 13\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:24 to store for rank: 12\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:24 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:23 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:24 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:23 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:23 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:24 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:24 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:23 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:24 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:23 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:24 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:24 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:25 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:24 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:25 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 15: Completed store-based barrier for key:store_based_barrier_key:24 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 8: Completed store-based barrier for key:store_based_barrier_key:24 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 10: Completed store-based barrier for key:store_based_barrier_key:24 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:24 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:25 to store for rank: 15\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 11: Completed store-based barrier for key:store_based_barrier_key:24 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 14: Completed store-based barrier for key:store_based_barrier_key:24 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:25 to store for rank: 8\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:25 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:25 to store for rank: 14\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:24 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:25 to store for rank: 10\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:25 to store for rank: 11\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 13: Completed store-based barrier for key:store_based_barrier_key:24 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 9: Completed store-based barrier for key:store_based_barrier_key:24 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 12: Completed store-based barrier for key:store_based_barrier_key:24 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:24 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:25 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:25 to store for rank: 13\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:25 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:25 to store for rank: 12\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:25 to store for rank: 9\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:24 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:24 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:25 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:25 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:24 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:25 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:25 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:26 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:25 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:26 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:25 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:26 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:25 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:26 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:25 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:25 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 15: Completed store-based barrier for key:store_based_barrier_key:25 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:26 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 8: Completed store-based barrier for key:store_based_barrier_key:25 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 14: Completed store-based barrier for key:store_based_barrier_key:25 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:25 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:26 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 10: Completed store-based barrier for key:store_based_barrier_key:25 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:25 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 11: Completed store-based barrier for key:store_based_barrier_key:25 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:26 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 13: Completed store-based barrier for key:store_based_barrier_key:25 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:26 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 12: Completed store-based barrier for key:store_based_barrier_key:25 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 9: Completed store-based barrier for key:store_based_barrier_key:25 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:26 to store for rank: 15\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:26 to store for rank: 14\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:26 to store for rank: 8\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:26 to store for rank: 13\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:26 to store for rank: 10\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:26 to store for rank: 12\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:26 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:26 to store for rank: 9\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:26 to store for rank: 11\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 8: Completed store-based barrier for key:store_based_barrier_key:26 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 13: Completed store-based barrier for key:store_based_barrier_key:26 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 10: Completed store-based barrier for key:store_based_barrier_key:26 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 11: Completed store-based barrier for key:store_based_barrier_key:26 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:27 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 12: Completed store-based barrier for key:store_based_barrier_key:26 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 9: Completed store-based barrier for key:store_based_barrier_key:26 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:27 to store for rank: 8\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:27 to store for rank: 13\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:27 to store for rank: 10\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:27 to store for rank: 9\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:27 to store for rank: 11\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:27 to store for rank: 12\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:26 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:27 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:26 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:26 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:27 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:26 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:27 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:26 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:27 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:27 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:26 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:26 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:27 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 15: Completed store-based barrier for key:store_based_barrier_key:26 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:27 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 14: Completed store-based barrier for key:store_based_barrier_key:26 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:27 to store for rank: 15\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:27 to store for rank: 14\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 15: Completed store-based barrier for key:store_based_barrier_key:27 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 13: Completed store-based barrier for key:store_based_barrier_key:27 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:27 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 14: Completed store-based barrier for key:store_based_barrier_key:27 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 9: Completed store-based barrier for key:store_based_barrier_key:27 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 10: Completed store-based barrier for key:store_based_barrier_key:27 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 8: Completed store-based barrier for key:store_based_barrier_key:27 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:28 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 11: Completed store-based barrier for key:store_based_barrier_key:27 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:28 to store for rank: 14\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:28 to store for rank: 15\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:28 to store for rank: 10\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:28 to store for rank: 13\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 12: Completed store-based barrier for key:store_based_barrier_key:27 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:28 to store for rank: 9\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:28 to store for rank: 8\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:28 to store for rank: 11\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:28 to store for rank: 12\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:27 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:28 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:27 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:27 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:28 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:28 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:27 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:27 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:28 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:28 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:27 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:27 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:28 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:28 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:28 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:29 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:28 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:29 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 14: Completed store-based barrier for key:store_based_barrier_key:28 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 10: Completed store-based barrier for key:store_based_barrier_key:28 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 13: Completed store-based barrier for key:store_based_barrier_key:28 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 15: Completed store-based barrier for key:store_based_barrier_key:28 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 9: Completed store-based barrier for key:store_based_barrier_key:28 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 11: Completed store-based barrier for key:store_based_barrier_key:28 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 8: Completed store-based barrier for key:store_based_barrier_key:28 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:29 to store for rank: 10\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:29 to store for rank: 13\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:29 to store for rank: 15\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:29 to store for rank: 14\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:29 to store for rank: 9\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 12: Completed store-based barrier for key:store_based_barrier_key:28 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:29 to store for rank: 11\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:29 to store for rank: 8\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:29 to store for rank: 12\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:28 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:29 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:28 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:28 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:29 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:29 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:28 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:29 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:28 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:28 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:29 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:29 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:29 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:29 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:30 to store for rank: 5\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:30 to store for rank: 3\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:29 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:30 to store for rank: 6\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:29 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:30 to store for rank: 7\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 10: Completed store-based barrier for key:store_based_barrier_key:29 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 13: Completed store-based barrier for key:store_based_barrier_key:29 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 9: Completed store-based barrier for key:store_based_barrier_key:29 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:30 to store for rank: 10\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 14: Completed store-based barrier for key:store_based_barrier_key:29 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 15: Completed store-based barrier for key:store_based_barrier_key:29 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 11: Completed store-based barrier for key:store_based_barrier_key:29 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:30 to store for rank: 13\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 8: Completed store-based barrier for key:store_based_barrier_key:29 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:30 to store for rank: 9\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 12: Completed store-based barrier for key:store_based_barrier_key:29 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:30 to store for rank: 14\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:30 to store for rank: 11\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:30 to store for rank: 15\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:30 to store for rank: 8\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:30 to store for rank: 12\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:29 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:30 to store for rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:29 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:29 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:30 to store for rank: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:30 to store for rank: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:29 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:30 to store for rank: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 2: Completed store-based barrier for key:store_based_barrier_key:30 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 5: Completed store-based barrier for key:store_based_barrier_key:30 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 3: Completed store-based barrier for key:store_based_barrier_key:30 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-04-12 21:14:39.464: I smdistributed/modelparallel/torch/state_mod.py:161] [2] Finished initializing torch distributed process groups. pp_rank: 0, tp_rank: 2, dp_rank: 2, rdp_rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-04-12 21:14:39.465: I smdistributed/modelparallel/torch/state_mod.py:161] [5] Finished initializing torch distributed process groups. pp_rank: 0, tp_rank: 5, dp_rank: 5, rdp_rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-04-12 21:14:39.465: I smdistributed/modelparallel/torch/state_mod.py:161] [3] Finished initializing torch distributed process groups. pp_rank: 0, tp_rank: 3, dp_rank: 3, rdp_rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 6: Completed store-based barrier for key:store_based_barrier_key:30 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-04-12 21:14:39.465: I smdistributed/modelparallel/torch/state_mod.py:161] [6] Finished initializing torch distributed process groups. pp_rank: 0, tp_rank: 6, dp_rank: 6, rdp_rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 7: Completed store-based barrier for key:store_based_barrier_key:30 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-04-12 21:14:39.465: I smdistributed/modelparallel/torch/state_mod.py:161] [7] Finished initializing torch distributed process groups. pp_rank: 0, tp_rank: 7, dp_rank: 7, rdp_rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 9: Completed store-based barrier for key:store_based_barrier_key:30 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 13: Completed store-based barrier for key:store_based_barrier_key:30 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 10: Completed store-based barrier for key:store_based_barrier_key:30 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:[2022-04-12 21:14:39.465: I smdistributed/modelparallel/torch/state_mod.py:161] [10] Finished initializing torch distributed process groups. pp_rank: 1, tp_rank: 2, dp_rank: 2, rdp_rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 14: Completed store-based barrier for key:store_based_barrier_key:30 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 11: Completed store-based barrier for key:store_based_barrier_key:30 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 15: Completed store-based barrier for key:store_based_barrier_key:30 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 8: Completed store-based barrier for key:store_based_barrier_key:30 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:[2022-04-12 21:14:39.465: I smdistributed/modelparallel/torch/state_mod.py:161] [13] Finished initializing torch distributed process groups. pp_rank: 1, tp_rank: 5, dp_rank: 5, rdp_rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:[2022-04-12 21:14:39.465: I smdistributed/modelparallel/torch/state_mod.py:161] [9] Finished initializing torch distributed process groups. pp_rank: 1, tp_rank: 1, dp_rank: 1, rdp_rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:[2022-04-12 21:14:39.465: I smdistributed/modelparallel/torch/state_mod.py:161] [11] Finished initializing torch distributed process groups. pp_rank: 1, tp_rank: 3, dp_rank: 3, rdp_rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:[2022-04-12 21:14:39.465: I smdistributed/modelparallel/torch/state_mod.py:161] [14] Finished initializing torch distributed process groups. pp_rank: 1, tp_rank: 6, dp_rank: 6, rdp_rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 12: Completed store-based barrier for key:store_based_barrier_key:30 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:[2022-04-12 21:14:39.465: I smdistributed/modelparallel/torch/state_mod.py:161] [8] Finished initializing torch distributed process groups. pp_rank: 1, tp_rank: 0, dp_rank: 0, rdp_rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:[2022-04-12 21:14:39.465: I smdistributed/modelparallel/torch/state_mod.py:161] [15] Finished initializing torch distributed process groups. pp_rank: 1, tp_rank: 7, dp_rank: 7, rdp_rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:[2022-04-12 21:14:39.465: I smdistributed/modelparallel/torch/state_mod.py:161] [12] Finished initializing torch distributed process groups. pp_rank: 1, tp_rank: 4, dp_rank: 4, rdp_rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:30 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:14:39.472: I smdistributed/modelparallel/torch/state_mod.py:161] [0] Finished initializing torch distributed process groups. pp_rank: 0, tp_rank: 0, dp_rank: 0, rdp_rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:14:39.472: I smdistributed/modelparallel/torch/throttler.py:37] Using NCCL throttle limit of 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 4: Completed store-based barrier for key:store_based_barrier_key:30 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:INFO:torch.distributed.distributed_c10d:Rank 1: Completed store-based barrier for key:store_based_barrier_key:30 with 16 nodes.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-04-12 21:14:39.474: I smdistributed/modelparallel/torch/state_mod.py:161] [4] Finished initializing torch distributed process groups. pp_rank: 0, tp_rank: 4, dp_rank: 4, rdp_rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-04-12 21:14:39.475: I smdistributed/modelparallel/torch/state_mod.py:161] [1] Finished initializing torch distributed process groups. pp_rank: 0, tp_rank: 1, dp_rank: 1, rdp_rank: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:14:39.602: I smdistributed/modelparallel/backend/config.py:230] Configuration parameters:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:14:39.602: I smdistributed/modelparallel/backend/config.py:233]   pipeline_parallel_degree: 2\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:14:39.602: I smdistributed/modelparallel/backend/config.py:233]   microbatches: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:14:39.602: I smdistributed/modelparallel/backend/config.py:233]   pipeline: interleaved\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:14:39.602: I smdistributed/modelparallel/backend/config.py:233]   horovod: False\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:14:39.602: I smdistributed/modelparallel/backend/config.py:233]   ddp: True\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:14:39.602: I smdistributed/modelparallel/backend/config.py:233]   tensor_parallel_degree: 8\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:14:39.602: I smdistributed/modelparallel/backend/config.py:233]   ddp_port: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:14:39.602: I smdistributed/modelparallel/backend/config.py:233]   ddp_dist_backend: nccl\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:14:39.602: I smdistributed/modelparallel/backend/config.py:233]   contiguous: True\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:14:39.602: I smdistributed/modelparallel/backend/config.py:233]   placement_strategy: cluster\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:14:39.603: I smdistributed/modelparallel/backend/config.py:233]   optimize: speed\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:14:39.603: I smdistributed/modelparallel/backend/config.py:233]   default_partition: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:14:39.603: I smdistributed/modelparallel/backend/config.py:233]   auto_partition: True\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:14:39.603: I smdistributed/modelparallel/backend/config.py:233]   prescaled_batch: True\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:14:39.603: I smdistributed/modelparallel/backend/config.py:233]   memory_weight: 0.8\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:14:39.603: I smdistributed/modelparallel/backend/config.py:233]   active_microbatches: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:14:39.603: I smdistributed/modelparallel/backend/config.py:233]   fp16_params: True\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:14:39.603: I smdistributed/modelparallel/backend/config.py:233]   tensor_parallel_seed: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:14:39.603: I smdistributed/modelparallel/backend/config.py:233]   offload_activations: False\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:14:39.603: I smdistributed/modelparallel/backend/config.py:233]   shard_optimizer_state: True\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:14:39.603: I smdistributed/modelparallel/backend/config.py:233]   skip_tracing: False\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:14:39.603: I smdistributed/modelparallel/backend/config.py:233]   activation_loading_horizon: 4\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Arguments:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:{'train_batch_size': 16, 'val_batch_size': 16, 'max_steps': 100, 'seed': 12345, 'same_seed': 0, 'n_gpus': '8', 'fp16': 1, 'fp32_grad_accumulation': 0, 'megatron': 0, 'grad_clip': 1.0, 'weight_decay': 0.01, 'beta1': 0.9, 'beta2': 0.95, 'activation_checkpointing': 1, 'logging_freq': 10, 'use_bert_data': 0, 'zipped_data': 1, 'epochs': 3, 'output_data_dir': '/opt/ml/output/data', 'checkpoint_dir': '/opt/ml/checkpoints', 'model_dir': '/opt/ml/model', 'training_dir': '/opt/ml/input/data/train', 'test_dir': '/opt/ml/input/data/test', 'parallel_proc_data_processing': 0, 'save_final_full_model': 1, 'skip_full_optimizer': 1, 'load_partial': 0, 'load_full': 0, 'logits_output': '', 'prescaled_batch': 1, 'max_context_width': 512, 'vocab_size': 50400, 'hidden_width': 4096, 'num_layers': 28, 'num_heads': 16, 'resid_pdrop': 0.1, 'embd_pdrop': 0.1, 'attn_pdrop': 0.1, 'summary_first_pdrop': 0.1, 'use_adamw': 0, 'tensor_parallel_degree': 8, 'pipeline_parallel_degree': 2, 'microbatches': 1, 'active_microbatches': None, 'optimize': 'speed', 'activation_strategy': 'each', 'shard_optimizer_state': 1, 'offload_activations': 0, 'fast_mode': 0, 'static_mode': 0, 'delayed_param': 0, 'same_partition_load': 0, 'attention_in_fp32': 0, 'placement_strategy': 'cluster', 'activation_loading_horizon': 4, 'skip_tracing': 0, 'query_key_layer_scaling': 1, 'fused_softmax': 1, 'fused_bias_gelu': 1, 'num_kept_checkpoints': 5, 'checkpoint_freq': 200, 'validation_freq': 1000, 'validation_batches': 10, 'manual_partition': 0, 'partition_assignment': '', 'match_weights': 0, 'preserve_np_state': 0, 'fast_validation': 1, 'gather_if_shard': 1, 'clean_cache': 0, 'use_fsx': 0, 'enable_memory_profiling': 0, 'lr': 0.0002, 'lr_decay_style': 'linear', 'lr_decay_iters': 125000, 'min_lr': 1e-05, 'warmup': 0.01, 'plateau': 0.4, 'ci': False, 'time_to_train': None, 'throughput': None, 'loss': None, 'save_or_verify_ckptsum': False}\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Transformers version: 4.17.0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:smdistributed.modelparallel version: 1.8.0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:smdistributed config: {'ddp': True, 'tensor_parallel_degree': 8, 'pipeline_parallel_degree': 2, 'microbatches': 1, 'checkpoint_attentions': False, 'shard_optimizer_state': True, 'prescaled_batch': True, '_match_weights': False, 'fp16_params': True, 'offload_activations': False, 'optimize': 'speed', 'placement_strategy': 'cluster', 'activation_loading_horizon': 4, 'skip_tracing': False, 'auto_partition': True, 'default_partition': 0, '_fp32_grad_accumulation': False, 'static_mode': False, 'fast_mode': False}\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[Warning] Note that save_final_full_model only saves the final model at the end of all steps. It does not save optimizer state. Optimizer state is only saved with partial models which are saved at checkpointing_freq during training. If you want to restart training you need partial checkpoints.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:# total parameters: 6050882784\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Learning rate decay style: linear\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Creating val dataloader\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:WARNING: Will not set fp16 gradients to None since shard_optimizer_state is enabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:WARNING: Will not set fp16 gradients to None since shard_optimizer_state is enabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:WARNING: Will not set fp16 gradients to None since shard_optimizer_state is enabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:WARNING: Will not set fp16 gradients to None since shard_optimizer_state is enabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Created val dataloader\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Reading data from training path ['/opt/ml/input/data/train/part-00001-synthetic.json.gz']\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:WARNING: Will not set fp16 gradients to None since shard_optimizer_state is enabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:WARNING: Will not set fp16 gradients to None since shard_optimizer_state is enabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:WARNING: Will not set fp16 gradients to None since shard_optimizer_state is enabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:WARNING: Will not set fp16 gradients to None since shard_optimizer_state is enabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:WARNING: Will not set fp16 gradients to None since shard_optimizer_state is enabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:WARNING: Will not set fp16 gradients to None since shard_optimizer_state is enabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-04-12 21:18:05.120: W smdistributed/modelparallel/backend/split.py:166] Non-splittable object of type <class 'fp16.fp16.FP16_Optimizer'> passed to smp.step. If this object contains tensors that need to be split across microbatches, implement a 'smp_slice' method for this class. See SMP documentation for further information.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-04-12 21:18:05.120: W smdistributed/modelparallel/backend/split.py:166] Non-splittable object of type <class 'fp16.fp16.FP16_Optimizer'> passed to smp.step. If this object contains tensors that need to be split across microbatches, implement a 'smp_slice' method for this class. See SMP documentation for further information.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-04-12 21:18:05.120: W smdistributed/modelparallel/backend/split.py:166] Non-splittable object of type <class 'fp16.fp16.FP16_Optimizer'> passed to smp.step. If this object contains tensors that need to be split across microbatches, implement a 'smp_slice' method for this class. See SMP documentation for further information.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-04-12 21:18:05.120: W smdistributed/modelparallel/backend/split.py:166] Non-splittable object of type <class 'fp16.fp16.FP16_Optimizer'> passed to smp.step. If this object contains tensors that need to be split across microbatches, implement a 'smp_slice' method for this class. See SMP documentation for further information.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:WARNING: Will not set fp16 gradients to None since shard_optimizer_state is enabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-04-12 21:18:05.131: W smdistributed/modelparallel/backend/split.py:166] Non-splittable object of type <class 'fp16.fp16.FP16_Optimizer'> passed to smp.step. If this object contains tensors that need to be split across microbatches, implement a 'smp_slice' method for this class. See SMP documentation for further information.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:WARNING: Will not set fp16 gradients to None since shard_optimizer_state is enabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:05.161: W smdistributed/modelparallel/backend/split.py:166] Non-splittable object of type <class 'fp16.fp16.FP16_Optimizer'> passed to smp.step. If this object contains tensors that need to be split across microbatches, implement a 'smp_slice' method for this class. See SMP documentation for further information.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:05.162: I smdistributed/modelparallel/torch/worker.py:296] Tracing on GPU. If the model parameters do not fit in a single GPU, you can set trace_device to `cpu`.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:WARNING: Will not set fp16 gradients to None since shard_optimizer_state is enabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:WARNING: Will not set fp16 gradients to None since shard_optimizer_state is enabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-04-12 21:18:05.253: W smdistributed/modelparallel/backend/split.py:166] Non-splittable object of type <class 'fp16.fp16.FP16_Optimizer'> passed to smp.step. If this object contains tensors that need to be split across microbatches, implement a 'smp_slice' method for this class. See SMP documentation for further information.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:WARNING: Will not set fp16 gradients to None since shard_optimizer_state is enabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:WARNING: Will not set fp16 gradients to None since shard_optimizer_state is enabled.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-04-12 21:18:05.439: W smdistributed/modelparallel/backend/split.py:166] Non-splittable object of type <class 'fp16.fp16.FP16_Optimizer'> passed to smp.step. If this object contains tensors that need to be split across microbatches, implement a 'smp_slice' method for this class. See SMP documentation for further information.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:07.889: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:07.907: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:08.394: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:08.399: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:08.403: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:08.407: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:08.412: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:08.416: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:08.420: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:08.425: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:08.429: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:08.433: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:08.438: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:08.442: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:08.446: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:08.450: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:08.455: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:08.460: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:08.464: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:08.468: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:08.473: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:08.477: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:08.481: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:08.485: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:08.490: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:08.494: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:08.498: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:08.502: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.080: I smdistributed/modelparallel/torch/model.py:493] Partition assignments:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.080: I smdistributed/modelparallel/torch/model.py:502] main: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.080: I smdistributed/modelparallel/torch/model.py:502] main/module: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.080: I smdistributed/modelparallel/torch/model.py:502] main/module/module: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.080: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.080: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/word_embedding: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.080: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/dropout: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.081: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/transformer: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.081: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/layernorm: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.081: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/ce_loss: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.081: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/lm_head: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.081: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/transformer/seq_layers: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.081: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/transformer/seq_layers/0: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.081: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/transformer/seq_layers/1: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.081: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/transformer/seq_layers/2: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.081: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/transformer/seq_layers/3: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.081: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/transformer/seq_layers/4: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.081: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/transformer/seq_layers/5: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.081: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/transformer/seq_layers/6: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.081: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/transformer/seq_layers/7: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.081: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/transformer/seq_layers/8: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.081: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/transformer/seq_layers/9: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.081: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/transformer/seq_layers/10: 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.081: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/transformer/seq_layers/11: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.081: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/transformer/seq_layers/12: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.082: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/transformer/seq_layers/13: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.082: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/transformer/seq_layers/14: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.082: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/transformer/seq_layers/15: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.082: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/transformer/seq_layers/16: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.082: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/transformer/seq_layers/17: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.082: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/transformer/seq_layers/18: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.082: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/transformer/seq_layers/19: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.082: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/transformer/seq_layers/20: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.082: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/transformer/seq_layers/21: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.082: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/transformer/seq_layers/22: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.082: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/transformer/seq_layers/23: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.082: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/transformer/seq_layers/24: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.082: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/transformer/seq_layers/25: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.082: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/transformer/seq_layers/26: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.082: I smdistributed/modelparallel/torch/model.py:502] main/module/module/module/transformer/seq_layers/27: 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.082: I smdistributed/modelparallel/torch/model.py:507] Tensor-parallel distributed modules:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.082: I smdistributed/modelparallel/torch/model.py:516] main/module/module/module\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:[2022-04-12 21:18:09.387: I smdistributed/modelparallel/torch/model.py:427] Number of parameters on partition 1 are 170. 170 require grads\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.391: I smdistributed/modelparallel/torch/model.py:427] Number of parameters on partition 0 are 115. 115 require grads\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:09.540: I smdistributed/modelparallel/torch/model.py:548] Finished partitioning the model\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:NCCL version 2.10.3+cuda11.3\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:NCCL version 2.10.3+cuda11.3\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:NCCL version 2.10.3+cuda11.3\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:NCCL version 2.10.3+cuda11.3\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:NCCL version 2.10.3+cuda11.3\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:NCCL version 2.10.3+cuda11.3\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:NCCL version 2.10.3+cuda11.3\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:NCCL version 2.10.3+cuda11.3\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:NCCL version 2.10.3+cuda11.3\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:NCCL version 2.10.3+cuda11.3\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:NCCL version 2.10.3+cuda11.3\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:NCCL version 2.10.3+cuda11.3\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:NCCL version 2.10.3+cuda11.3\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:NCCL version 2.10.3+cuda11.3\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:NCCL version 2.10.3+cuda11.3\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:NCCL version 2.10.3+cuda11.3\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:[2022-04-12 21:18:13.966: I smdistributed/modelparallel/torch/model.py:556] Broadcasted parameters and buffers for partition 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:14.016: I smdistributed/modelparallel/torch/model.py:556] Broadcasted parameters and buffers for partition 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:[2022-04-12 21:18:24.255: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:[2022-04-12 21:18:24.273: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:[2022-04-12 21:18:24.711: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:[2022-04-12 21:18:24.717: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:[2022-04-12 21:18:24.723: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:[2022-04-12 21:18:24.730: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:[2022-04-12 21:18:24.737: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:[2022-04-12 21:18:24.745: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:[2022-04-12 21:18:24.752: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:[2022-04-12 21:18:24.760: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:[2022-04-12 21:18:24.767: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:[2022-04-12 21:18:24.774: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:[2022-04-12 21:18:24.781: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:[2022-04-12 21:18:24.788: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:[2022-04-12 21:18:24.796: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:[2022-04-12 21:18:24.814: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:[2022-04-12 21:18:24.821: W smdistributed/modelparallel/torch/nn/transformer.py:1469] Using fused softmax kernel in attention computation, which ignores the attention mask input. To use an attention mask that masks at least one token, disable the fused softmax kernel by passing fused_softmax=False into the smp.tensor_parallelism or smp.set_tensor_parallelism calls.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-04-12 21:18:26.089: I smdistributed/modelparallel/torch/ddp_model.py:630] [6] Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-04-12 21:18:26.089: I smdistributed/modelparallel/torch/ddp_model.py:630] [2] Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-04-12 21:18:26.089: I smdistributed/modelparallel/torch/ddp_model.py:630] [3] Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-04-12 21:18:26.090: I smdistributed/modelparallel/torch/ddp_model.py:630] [7] Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-04-12 21:18:26.090: I smdistributed/modelparallel/torch/ddp_model.py:630] [5] Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-04-12 21:18:26.090: I smdistributed/modelparallel/torch/ddp_model.py:630] [4] Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-04-12 21:18:26.090: I smdistributed/modelparallel/torch/ddp_model.py:630] [1] Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:26.090: I smdistributed/modelparallel/torch/ddp_model.py:630] [0] Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:[2022-04-12 21:18:26.091: I smdistributed/modelparallel/torch/ddp_model.py:630] [8] Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:[2022-04-12 21:18:26.092: I smdistributed/modelparallel/torch/ddp_model.py:630] [10] Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:[2022-04-12 21:18:26.092: I smdistributed/modelparallel/torch/ddp_model.py:630] [14] Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:[2022-04-12 21:18:26.092: I smdistributed/modelparallel/torch/ddp_model.py:630] [12] Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:[2022-04-12 21:18:26.092: I smdistributed/modelparallel/torch/ddp_model.py:630] [13] Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:[2022-04-12 21:18:26.093: I smdistributed/modelparallel/torch/ddp_model.py:630] [8] Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:[2022-04-12 21:18:26.093: I smdistributed/modelparallel/torch/ddp_model.py:630] [9] Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:[2022-04-12 21:18:26.093: I smdistributed/modelparallel/torch/ddp_model.py:630] [11] Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:[2022-04-12 21:18:26.093: I smdistributed/modelparallel/torch/ddp_model.py:630] [15] Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:[2022-04-12 21:18:26.094: I smdistributed/modelparallel/torch/ddp_model.py:630] [10] Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:[2022-04-12 21:18:26.094: I smdistributed/modelparallel/torch/ddp_model.py:630] [9] Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:[2022-04-12 21:18:26.094: I smdistributed/modelparallel/torch/ddp_model.py:630] [13] Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:[2022-04-12 21:18:26.094: I smdistributed/modelparallel/torch/ddp_model.py:630] [14] Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:[2022-04-12 21:18:26.094: I smdistributed/modelparallel/torch/ddp_model.py:630] [11] Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:[2022-04-12 21:18:26.094: I smdistributed/modelparallel/torch/ddp_model.py:630] [12] Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:[2022-04-12 21:18:26.094: I smdistributed/modelparallel/torch/ddp_model.py:630] [15] Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-04-12 21:18:26.107: I smdistributed/modelparallel/torch/ddp_model.py:630] [2] Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:18:26.107: I smdistributed/modelparallel/torch/ddp_model.py:630] [0] Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-04-12 21:18:26.108: I smdistributed/modelparallel/torch/ddp_model.py:630] [1] Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-04-12 21:18:26.108: I smdistributed/modelparallel/torch/ddp_model.py:630] [6] Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-04-12 21:18:26.108: I smdistributed/modelparallel/torch/ddp_model.py:630] [4] Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-04-12 21:18:26.108: I smdistributed/modelparallel/torch/ddp_model.py:630] [5] Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-04-12 21:18:26.108: I smdistributed/modelparallel/torch/ddp_model.py:630] [3] Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-04-12 21:18:26.108: I smdistributed/modelparallel/torch/ddp_model.py:630] [7] Reducer buckets have been rebuilt in this iteration.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:(34s), Batch 9 Loss: 10.8359375, Speed: 15.794319691291253 samples/sec\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:(45s), Batch 19 Loss: 10.8671875, Speed: 12.390117131145452 samples/sec\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:(56s), Batch 29 Loss: 10.84375, Speed: 15.60102725355667 samples/sec\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:(66s), Batch 39 Loss: 10.8671875, Speed: 15.505916886324062 samples/sec\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:(77s), Batch 49 Loss: 10.8203125, Speed: 15.226126669632835 samples/sec\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:(88s), Batch 59 Loss: 10.8125, Speed: 15.649176416378209 samples/sec\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:(98s), Batch 69 Loss: 10.84375, Speed: 15.770490940332909 samples/sec\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:(109s), Batch 79 Loss: 10.828125, Speed: 15.554608237893346 samples/sec\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:(120s), Batch 89 Loss: 10.8203125, Speed: 14.937066498337108 samples/sec\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:(130s), Batch 99 Loss: 10.8125, Speed: 15.612968638363698 samples/sec\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:[2022-04-12 21:20:16.209: I smdistributed/modelparallel/torch/model.py:672] [15] Gathering model state_dict during saving. To prevent hangs, please ensure that model.state_dict() (where model is smp.DistributedModel wrapped model) is called on all the ranks with rdp_rank() == 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:[2022-04-12 21:20:16.209: W smdistributed/modelparallel/torch/model.py:682] [15] gather_to_rank0 is set to True. Full state_dict will only be saved to rank 0 only, other ranks will have empty dicts\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:[2022-04-12 21:20:16.226: I smdistributed/modelparallel/torch/model.py:672] [13] Gathering model state_dict during saving. To prevent hangs, please ensure that model.state_dict() (where model is smp.DistributedModel wrapped model) is called on all the ranks with rdp_rank() == 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:[2022-04-12 21:20:16.226: W smdistributed/modelparallel/torch/model.py:682] [13] gather_to_rank0 is set to True. Full state_dict will only be saved to rank 0 only, other ranks will have empty dicts\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:[2022-04-12 21:20:16.283: I smdistributed/modelparallel/torch/model.py:672] [11] Gathering model state_dict during saving. To prevent hangs, please ensure that model.state_dict() (where model is smp.DistributedModel wrapped model) is called on all the ranks with rdp_rank() == 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:[2022-04-12 21:20:16.284: W smdistributed/modelparallel/torch/model.py:682] [11] gather_to_rank0 is set to True. Full state_dict will only be saved to rank 0 only, other ranks will have empty dicts\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:[2022-04-12 21:20:16.309: I smdistributed/modelparallel/torch/model.py:672] [9] Gathering model state_dict during saving. To prevent hangs, please ensure that model.state_dict() (where model is smp.DistributedModel wrapped model) is called on all the ranks with rdp_rank() == 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:[2022-04-12 21:20:16.309: W smdistributed/modelparallel/torch/model.py:682] [9] gather_to_rank0 is set to True. Full state_dict will only be saved to rank 0 only, other ranks will have empty dicts\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:[2022-04-12 21:20:16.313: I smdistributed/modelparallel/torch/model.py:672] [12] Gathering model state_dict during saving. To prevent hangs, please ensure that model.state_dict() (where model is smp.DistributedModel wrapped model) is called on all the ranks with rdp_rank() == 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:[2022-04-12 21:20:16.313: W smdistributed/modelparallel/torch/model.py:682] [12] gather_to_rank0 is set to True. Full state_dict will only be saved to rank 0 only, other ranks will have empty dicts\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:[2022-04-12 21:20:16.331: I smdistributed/modelparallel/torch/model.py:672] [8] Gathering model state_dict during saving. To prevent hangs, please ensure that model.state_dict() (where model is smp.DistributedModel wrapped model) is called on all the ranks with rdp_rank() == 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:[2022-04-12 21:20:16.331: W smdistributed/modelparallel/torch/model.py:682] [8] gather_to_rank0 is set to True. Full state_dict will only be saved to rank 0 only, other ranks will have empty dicts\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:[2022-04-12 21:20:16.349: I smdistributed/modelparallel/torch/model.py:672] [10] Gathering model state_dict during saving. To prevent hangs, please ensure that model.state_dict() (where model is smp.DistributedModel wrapped model) is called on all the ranks with rdp_rank() == 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:[2022-04-12 21:20:16.349: W smdistributed/modelparallel/torch/model.py:682] [10] gather_to_rank0 is set to True. Full state_dict will only be saved to rank 0 only, other ranks will have empty dicts\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:[2022-04-12 21:20:16.351: I smdistributed/modelparallel/torch/model.py:672] [14] Gathering model state_dict during saving. To prevent hangs, please ensure that model.state_dict() (where model is smp.DistributedModel wrapped model) is called on all the ranks with rdp_rank() == 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:[2022-04-12 21:20:16.351: W smdistributed/modelparallel/torch/model.py:682] [14] gather_to_rank0 is set to True. Full state_dict will only be saved to rank 0 only, other ranks will have empty dicts\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-04-12 21:20:16.621: I smdistributed/modelparallel/torch/model.py:672] [2] Gathering model state_dict during saving. To prevent hangs, please ensure that model.state_dict() (where model is smp.DistributedModel wrapped model) is called on all the ranks with rdp_rank() == 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2022-04-12 21:20:16.622: W smdistributed/modelparallel/torch/model.py:682] [2] gather_to_rank0 is set to True. Full state_dict will only be saved to rank 0 only, other ranks will have empty dicts\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-04-12 21:20:16.649: I smdistributed/modelparallel/torch/model.py:672] [1] Gathering model state_dict during saving. To prevent hangs, please ensure that model.state_dict() (where model is smp.DistributedModel wrapped model) is called on all the ranks with rdp_rank() == 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2022-04-12 21:20:16.650: W smdistributed/modelparallel/torch/model.py:682] [1] gather_to_rank0 is set to True. Full state_dict will only be saved to rank 0 only, other ranks will have empty dicts\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-04-12 21:20:16.656: I smdistributed/modelparallel/torch/model.py:672] [6] Gathering model state_dict during saving. To prevent hangs, please ensure that model.state_dict() (where model is smp.DistributedModel wrapped model) is called on all the ranks with rdp_rank() == 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:[2022-04-12 21:20:16.656: W smdistributed/modelparallel/torch/model.py:682] [6] gather_to_rank0 is set to True. Full state_dict will only be saved to rank 0 only, other ranks will have empty dicts\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-04-12 21:20:16.673: I smdistributed/modelparallel/torch/model.py:672] [4] Gathering model state_dict during saving. To prevent hangs, please ensure that model.state_dict() (where model is smp.DistributedModel wrapped model) is called on all the ranks with rdp_rank() == 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-04-12 21:20:16.673: I smdistributed/modelparallel/torch/model.py:672] [7] Gathering model state_dict during saving. To prevent hangs, please ensure that model.state_dict() (where model is smp.DistributedModel wrapped model) is called on all the ranks with rdp_rank() == 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:[2022-04-12 21:20:16.673: W smdistributed/modelparallel/torch/model.py:682] [7] gather_to_rank0 is set to True. Full state_dict will only be saved to rank 0 only, other ranks will have empty dicts\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:[2022-04-12 21:20:16.673: W smdistributed/modelparallel/torch/model.py:682] [4] gather_to_rank0 is set to True. Full state_dict will only be saved to rank 0 only, other ranks will have empty dicts\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-04-12 21:20:16.680: I smdistributed/modelparallel/torch/model.py:672] [5] Gathering model state_dict during saving. To prevent hangs, please ensure that model.state_dict() (where model is smp.DistributedModel wrapped model) is called on all the ranks with rdp_rank() == 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:[2022-04-12 21:20:16.680: W smdistributed/modelparallel/torch/model.py:682] [5] gather_to_rank0 is set to True. Full state_dict will only be saved to rank 0 only, other ranks will have empty dicts\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-04-12 21:20:16.723: I smdistributed/modelparallel/torch/model.py:672] [3] Gathering model state_dict during saving. To prevent hangs, please ensure that model.state_dict() (where model is smp.DistributedModel wrapped model) is called on all the ranks with rdp_rank() == 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2022-04-12 21:20:16.723: W smdistributed/modelparallel/torch/model.py:682] [3] gather_to_rank0 is set to True. Full state_dict will only be saved to rank 0 only, other ranks will have empty dicts\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:20:16.756: I smdistributed/modelparallel/torch/model.py:672] [0] Gathering model state_dict during saving. To prevent hangs, please ensure that model.state_dict() (where model is smp.DistributedModel wrapped model) is called on all the ranks with rdp_rank() == 0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2022-04-12 21:20:16.756: W smdistributed/modelparallel/torch/model.py:682] [0] gather_to_rank0 is set to True. Full state_dict will only be saved to rank 0 only, other ranks will have empty dicts\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:Skipping saving the final optimizer state\u001b[0m\n",
      "\u001b[34m[1,mpirank:9,algo-2]<stdout>:Finished checkpointing after 100 steps: /opt/ml/model/trained_gpt_nparams-6050882784_steps-100.pt\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:Skipping saving the final optimizer state\u001b[0m\n",
      "\u001b[34m[1,mpirank:10,algo-2]<stdout>:Finished checkpointing after 100 steps: /opt/ml/model/trained_gpt_nparams-6050882784_steps-100.pt\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:Skipping saving the final optimizer state\u001b[0m\n",
      "\u001b[34m[1,mpirank:11,algo-2]<stdout>:Finished checkpointing after 100 steps: /opt/ml/model/trained_gpt_nparams-6050882784_steps-100.pt\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Skipping saving the final optimizer state\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Finished checkpointing after 100 steps: /opt/ml/model/trained_gpt_nparams-6050882784_steps-100.pt\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:Skipping saving the final optimizer state\u001b[0m\n",
      "\u001b[34m[1,mpirank:12,algo-2]<stdout>:Finished checkpointing after 100 steps: /opt/ml/model/trained_gpt_nparams-6050882784_steps-100.pt\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:Skipping saving the final optimizer state\u001b[0m\n",
      "\u001b[34m[1,mpirank:13,algo-2]<stdout>:Finished checkpointing after 100 steps: /opt/ml/model/trained_gpt_nparams-6050882784_steps-100.pt\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Skipping saving the final optimizer state\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Finished checkpointing after 100 steps: /opt/ml/model/trained_gpt_nparams-6050882784_steps-100.pt\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:Skipping saving the final optimizer state\u001b[0m\n",
      "\u001b[34m[1,mpirank:14,algo-2]<stdout>:Finished checkpointing after 100 steps: /opt/ml/model/trained_gpt_nparams-6050882784_steps-100.pt\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Skipping saving the final optimizer state\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Finished checkpointing after 100 steps: /opt/ml/model/trained_gpt_nparams-6050882784_steps-100.pt\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:Skipping saving the final optimizer state\u001b[0m\n",
      "\u001b[34m[1,mpirank:15,algo-2]<stdout>:Finished checkpointing after 100 steps: /opt/ml/model/trained_gpt_nparams-6050882784_steps-100.pt\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Skipping saving the final optimizer state\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-1]<stdout>:Finished checkpointing after 100 steps: /opt/ml/model/trained_gpt_nparams-6050882784_steps-100.pt\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Skipping saving the final optimizer state\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-1]<stdout>:Finished checkpointing after 100 steps: /opt/ml/model/trained_gpt_nparams-6050882784_steps-100.pt\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Skipping saving the final optimizer state\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-1]<stdout>:Finished checkpointing after 100 steps: /opt/ml/model/trained_gpt_nparams-6050882784_steps-100.pt\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Skipping saving the final optimizer state\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-1]<stdout>:Finished checkpointing after 100 steps: /opt/ml/model/trained_gpt_nparams-6050882784_steps-100.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Skipping saving the final optimizer state\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:Skipping saving the final optimizer state\u001b[0m\n",
      "\u001b[34m[1,mpirank:8,algo-2]<stdout>:Finished checkpointing after 100 steps: /opt/ml/model/trained_gpt_nparams-6050882784_steps-100.pt\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Finished checkpointing after 100 steps: /opt/ml/model/trained_gpt_nparams-6050882784_steps-100.pt\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:SMP training finished successfully\u001b[0m\n",
      "\u001b[35m2022-04-12 21:20:53,166 sagemaker-training-toolkit INFO     Orted process exited\u001b[0m\n",
      "\u001b[34m2022-04-12 21:20:53,145 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\u001b[35m2022-04-12 21:21:23,194 sagemaker-training-toolkit INFO     MPI process finished.\u001b[0m\n",
      "\u001b[35m2022-04-12 21:21:23,194 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-04-12 21:21:25 Uploading - Uploading generated training model\n",
      "2022-04-12 21:38:34 Completed - Training job completed\n",
      "Training seconds: 3448\n",
      "Billable seconds: 3448\n"
     ]
    }
   ],
   "source": [
    "smp_estimator.fit(inputs=data_channels, \n",
    "                  experiment_config={\n",
    "                    \"ExperimentName\": experiment.experiment_name,\n",
    "                    \"TrialName\": trial.trial_name,\n",
    "                    \"TrialComponentDisplayName\": \"Training\",\n",
    "                  },\n",
    "                  logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing the Training Logs\n",
    "\n",
    "You can access the training logs from [Amazon CloudWatch](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/WhatIsCloudWatch.html). Make sure to look at the logs of algo-1 as that is the master node whose output stream will have the training job logs.\n",
    "\n",
    "You can use CloudWatch to track SageMaker GPU and memory utilization during training and inference. To view the metrics and logs that SageMaker writes to CloudWatch, see *Processing Job, Training Job, Batch Transform Job, and Endpoint Instance Metrics* in [Monitor Amazon SageMaker with Amazon CloudWatch](https://docs.aws.amazon.com/sagemaker/latest/dg/monitoring-cloudwatch.html).\n",
    "\n",
    "If you are a new user of CloudWatch, see [Getting Started with Amazon CloudWatch](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/GettingStarted.html). \n",
    "\n",
    "For additional information on monitoring and analyzing Amazon SageMaker training jobs, see [Monitor and Analyze Training Jobs Using Metrics](https://docs.aws.amazon.com/sagemaker/latest/dg/training-metrics.html).\n",
    "\n",
    "# Deploying Trained Model for Inference\n",
    "\n",
    "In most cases the trained model can be deployed on a single device for inference, since inference has smaller memory requirements. You can use the SMP API to create a single, unified model after training. For TensorFlow, a SavedModel can be created using `smp.DistributedModel.save_model` API, and for PyTorch, `smp.save()` can be used.\n",
    "\n",
    "After you build and train your models, you can deploy them to get predictions in one of two ways:\n",
    "\n",
    "* To set up a persistent endpoint to get predictions from your models, use SageMaker hosting services. For an overview on deploying a single model or multiple models with SageMaker hosting services, see [Deploy a Model on SageMaker Hosting Services](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-deployment.html#how-it-works-hosting).\n",
    "* To get predictions for an entire dataset, use SageMaker batch transform. For an overview on deploying a model with SageMaker batch transform, see [Get Inferences for an Entire Dataset with Batch Transform](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html).\n",
    "\n",
    "To learn more about deploying models for inference using SageMaker, see [Deploy Models for Inference](https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html). \n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
